{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ue8ts-4k0Wvt"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10\n",
    "from sklearn import metrics\n",
    "from tensorly import decomposition\n",
    "import torch\n",
    "from torch.functional import tensordot\n",
    "from torch import nn, optim, Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data, download_url, extract_zip\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYW0MwN31fdW",
    "outputId": "5a6fff13-7ea1-43fe-eb22-68962914b762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.11.0\n",
      "Torch version: 1.11.0\n",
      "Cuda available: False\n",
      "Torch geometric version: 2.0.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch has version {torch.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl2uLQvH_Vpf"
   },
   "source": [
    "# Configurations\n",
    "\n",
    "Configure the model and training process. These parameters will make more sense as you move along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_nAUZ8LY0wyI"
   },
   "outputs": [],
   "source": [
    "rating_threshold = 3  #@param {type: \"integer\"}: Ratings equal to or greater than 3 are positive items.\n",
    "\n",
    "config_dict = {\n",
    "    \"num_samples_per_user\": 500,\n",
    "    \"num_users\": 200,\n",
    "\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.1,\n",
    "\n",
    "    \"embedding_size\": 64,\n",
    "    \"num_layers\": 5,\n",
    "    \"K\": 10,\n",
    "    \"mf_rank\": 8,\n",
    "\n",
    "    \"minibatch_per_print\": 100,\n",
    "    \"epochs_per_print\": 1,\n",
    "\n",
    "    \"val_frac\": 0.2,\n",
    "    \"test_frac\": 0.1,\n",
    "\n",
    "    \"model_name\": \"model.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpZBeK9B_Z9Q"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "A great publicly available dataset for training movie recommenders is the MovieLens 1M dataset. The MovieLens 1M dataset consists of 1 million movie ratings of score 1 to 5, from 6000 users and 4000 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8aFE4Jbg14IS"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IaZK6fwHzyd_"
   },
   "outputs": [],
   "source": [
    "def trans_ml(dat, thres):\n",
    "    \"\"\"\n",
    "    Transform function that assign non-negative entries >= thres 1, and non-\n",
    "    negative entries <= thres 0. Keep other entries the same.\n",
    "    \"\"\"\n",
    "    thres = thres[0]\n",
    "    matrix = dat['edge_index']\n",
    "    matrix[(matrix < thres) & (matrix > -1)] = 0\n",
    "    matrix[(matrix >= thres)] = 1\n",
    "    dat['edge_index'] = matrix\n",
    "    return dat\n",
    "\n",
    "\n",
    "class MovieLens(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None,\n",
    "            transform_args=None, pre_transform_args=None):\n",
    "        \"\"\"\n",
    "        root = where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (process data).\n",
    "        \"\"\"\n",
    "        super(MovieLens, self).__init__(root, transform, pre_transform)\n",
    "        self.transform = transform\n",
    "        self.pre_transform = pre_transform\n",
    "        self.transform_args = transform_args\n",
    "        self.pre_transform_args = pre_transform_args\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return \"ml-1m.zip\"\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data_movielens.pt\"]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        download_url(DATA_PATH, self.raw_dir)\n",
    "\n",
    "    def _load(self):\n",
    "        print(self.raw_dir)\n",
    "        # extract_zip(self.raw_paths[0], self.raw_dir)\n",
    "        with zipfile.ZipFile(self.raw_paths[0], 'r') as zip_ref:\n",
    "            zip_ref.extractall(self.raw_dir)\n",
    "        unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "        users = pd.read_table(self.raw_dir+'/ml-1m/users.dat', \n",
    "                              sep='::', header=None, names=unames,\n",
    "                              engine='python', encoding='latin-1')\n",
    "        rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "        ratings = pd.read_table(self.raw_dir+'/ml-1m/ratings.dat', sep='::', \n",
    "                                header=None, names=rnames, engine='python',\n",
    "                                encoding='latin-1')\n",
    "        mnames = ['movie_id', 'title', 'genres']\n",
    "        movies = pd.read_table(self.raw_dir+'/ml-1m/movies.dat', sep='::', \n",
    "                               header=None, names=mnames, engine='python',\n",
    "                               encoding='latin-1')\n",
    "        dat = pd.merge(pd.merge(ratings, users), movies)\n",
    "#         pdb.set_trace()\n",
    "        return users, ratings, movies, dat\n",
    "\n",
    "    def process(self):\n",
    "        print('run process')\n",
    "        # load information from file\n",
    "        users, ratings, movies, dat = self._load()\n",
    "\n",
    "        users = users['user_id']\n",
    "        movies = movies['movie_id']\n",
    "\n",
    "        num_users = config_dict[\"num_users\"]\n",
    "        if num_users != -1:\n",
    "            users = users[:num_users]\n",
    "\n",
    "        user_ids = range(len(users))\n",
    "        movie_ids = range(len(movies))\n",
    "\n",
    "        user_to_id = dict(zip(users, user_ids))\n",
    "        movie_to_id = dict(zip(movies, movie_ids))\n",
    "\n",
    "        # get adjacency info\n",
    "        self.num_user = users.shape[0]\n",
    "        self.num_item = movies.shape[0]\n",
    "\n",
    "        # initialize the adjacency matrix\n",
    "        rat = torch.zeros(self.num_user, self.num_item)\n",
    "\n",
    "        for index, row in ratings.iterrows():\n",
    "            user, movie, rating = row[:3]\n",
    "            if num_users != -1:\n",
    "                if user not in user_to_id: break\n",
    "            # create ratings matrix where (i, j) entry represents the ratings\n",
    "            # of movie j given by user i.\n",
    "            rat[user_to_id[user], movie_to_id[movie]] = rating\n",
    "        \n",
    "        # create Data object\n",
    "        data = Data(edge_index = rat,\n",
    "                    raw_edge_index = rat.clone(),\n",
    "                    data = ratings,\n",
    "                    users = users,\n",
    "                    items = movies)\n",
    "\n",
    "        # apply any pre-transformation\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data, self.pre_transform_args)\n",
    "\n",
    "        # apply any post_transformation\n",
    "        # if self.transform is not None:\n",
    "        #     # data = self.transform(data, self.transform_args)\n",
    "        data = self.transform(data, [rating_threshold])\n",
    "\n",
    "        # save the processed data into .pt file\n",
    "        torch.save(data, osp.join(self.processed_dir, f'data_movielens.pt'))\n",
    "        \n",
    "        \n",
    "        print('process finished')\n",
    "        \n",
    "      \n",
    "    def len(self):\n",
    "        \"\"\"\n",
    "        return the number of examples in your graph\n",
    "        \"\"\"\n",
    "        # TODO: how to define number of examples\n",
    "        return \n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"\n",
    "        The logic to load a single graph\n",
    "        \"\"\"\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_movielens.pt'))\n",
    "        return data\n",
    "\n",
    "    def train_val_test_split(self, val_frac=0.2, test_frac=0.1):\n",
    "        \"\"\"\n",
    "        Return two mask matrices (M, N) that represents edges present in the\n",
    "        train and validation set\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.num_user, self.num_item\n",
    "        except AttributeError:\n",
    "            data = self.get()\n",
    "            self.num_user = len(data[\"users\"].unique())\n",
    "            self.num_item = len(data[\"items\"].unique())\n",
    "        # get number of edges masked for training and validation\n",
    "        num_train_replaced = \\\n",
    "            round((test_frac+val_frac)*self.num_user*self.num_item)\n",
    "        num_val_show = round(val_frac*self.num_user*self.num_item)\n",
    "\n",
    "        # edges masked during training\n",
    "        indices_user = np.random.randint(0, self.num_user, num_train_replaced)\n",
    "        indices_item = np.random.randint(0, self.num_item, num_train_replaced)\n",
    "        \n",
    "        # sample part of edges from training stage to be unmasked during\n",
    "        # validation\n",
    "        indices_val_user = np.random.choice(indices_user, num_val_show)\n",
    "        indices_val_item = np.random.choice(indices_item, num_val_show)\n",
    "\n",
    "        train_mask = torch.ones(self.num_user, self.num_item)\n",
    "        train_mask[indices_user, indices_item] = 0\n",
    "\n",
    "        val_mask = train_mask.clone()\n",
    "        val_mask[indices_val_user, indices_val_item] = 1\n",
    "\n",
    "        test_mask = torch.ones_like(train_mask)\n",
    "#         pdb.set_trace()\n",
    "        return train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo-HN_lZ_8w1"
   },
   "source": [
    "# LightGCN implementation\n",
    "\n",
    "Now let's dive into the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEhZbrpVBeFo"
   },
   "source": [
    "## LightGCN neighborhood aggregation layer\n",
    "\n",
    "Starting with the initial embeddings $E^{(0)}$ and the bipartite graph, we iterate over each node to perform neighborhood aggregation. Note that LightGCN uses **a simple weighted sum aggregator** and **avoids the heavy-lifting feature transformation and nonlinear activation**.\n",
    "\n",
    "Within each layer, for each user in the graph, we compute its updated embedding as the weighted sum of embeddings from all its neighboring items (movies) following the formula below:\n",
    "$$ \\textbf{e}_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|} \\sqrt{|N_i|}} \\textbf{e}_i^{(k)} $$\n",
    "where $ \\textbf{e}_u^{(k)} $ and $ \\textbf{e}_i^{(k)} $ are the user and item (movie) node embeddings at the k-th layer. $ |N_u| $ and $ |N_i| $ are the user and item nodes’ number of neighbors.\n",
    "\n",
    "Similarly, for each item, the updated embedding is computed using weighted sum of its neighboring users:\n",
    "$$ \\textbf{e}_i^{(k+1)} = \\sum_{i \\in N_i} \\frac{1}{\\sqrt{|N_i|} \\sqrt{|N_u|}} \\textbf{e}_u^{(k)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WLlXODVwzkJ9"
   },
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
    "    Powering Graph Convolution Network for Recommendation\"\n",
    "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_users (int): Number of users for recommendation.\n",
    "        num_items (int): Number of items to recommend.\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 num_users: int, num_items: int, **kwargs):\n",
    "        super(LightGCNConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass  # There are no layer parameters to learn.\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
    "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
    "        user_item = \\\n",
    "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
    "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1\n",
    "        user_neighbor_counts = torch.sum(user_item, axis=1)\n",
    "        item_neightbor_counts = torch.sum(user_item, axis=0)\n",
    "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
    "        weights = user_item / torch.sqrt(\n",
    "                user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
    "                * item_neightbor_counts.repeat(self.num_users, 1))\n",
    "        weights = torch.nan_to_num(weights, nan=0)\n",
    "        out = torch.concat((weights.T @ x[:self.num_users],\n",
    "                            weights @ x[self.num_users:]), 0)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWt5WAIjBiQw"
   },
   "source": [
    "## LightGCN model\n",
    "\n",
    "At layer combination, instead of taking the embedding of the final layer, LightGCN computes **a weighted sum of the embeddings at different layers**:\n",
    "$$ \\textbf{e}_u = \\sum_{k=0}^K \\alpha_k \\textbf{e}_u^{(k)} $$\n",
    "$$ \\textbf{e}_i = \\sum_{k=0}^K \\alpha_k \\textbf{e}_i^{(k)} $$\n",
    "with $ \\alpha \\ge 0 $. Here, alpha values can either be learned as network parameters, or set as empirical hyperparameters. It has been found that $ \\alpha = \\frac{1}{K + 1} $ works well.\n",
    "\n",
    "LightGCN predicts based on the inner product of the final user and item (movie) embeddings:\n",
    "$$ \\hat{y}_{ui} = \\textbf{e}_u^T \\textbf{e}_i $$\n",
    "This inner product measures the similarity between the user and movie, therefore allowing us to understand how likely it is for the user to like the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wz80KhdizkOz"
   },
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 config: dict,\n",
    "                 device=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users  = config[\"n_users\"]\n",
    "        self.num_items  = config[\"m_items\"]\n",
    "        self.embedding_size = config[\"embedding_size\"]\n",
    "        self.in_channels = self.embedding_size\n",
    "        self.out_channels = self.embedding_size\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "\n",
    "        # 0-th layer embedding.\n",
    "        self.embedding_user_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users + self.num_items,\n",
    "            embedding_dim=self.embedding_size)\n",
    "        self.alpha = None\n",
    "\n",
    "        # random normal init seems to be a better choice when lightGCN actually\n",
    "        # don't use any non-linear activation function\n",
    "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
    "        print('use NORMAL distribution initilizer')\n",
    "\n",
    "        self.f = nn.Sigmoid()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(LightGCNConv(\n",
    "                self.embedding_size, self.embedding_size,\n",
    "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
    "\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.convs.append(\n",
    "                LightGCNConv(\n",
    "                        self.embedding_size, self.embedding_size, \n",
    "                        num_users=self.num_users, num_items=self.num_items,\n",
    "                        **kwargs))\n",
    "\n",
    "        self.device = None\n",
    "        if device is not None:\n",
    "            self.convs.to(device)\n",
    "            self.device = device\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
    "        xs: List[Tensor] = []\n",
    "\n",
    "        edge_index = torch.nonzero(edge_index)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
    "            if self.device is not None:\n",
    "                x = x.to(self.device)\n",
    "            xs.append(x)\n",
    "        xs = torch.stack(xs)\n",
    "        \n",
    "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
    "        if self.device is not None:\n",
    "            self.alpha = self.alpha.to(self.device)\n",
    "            xs = xs.to(self.device)\n",
    "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
    "        return x\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_layers={self.num_layers})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkRJgY39BkLI"
   },
   "source": [
    "## Utility functions\n",
    "\n",
    "The utility functions allow us to retrieve embeddings and compute user-item similarities. These will become userful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yCHmRyqw_s0D"
   },
   "outputs": [],
   "source": [
    "def getUsersRating(model, users, data):\n",
    "    \"\"\" Get the embedding of users\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "    \"\"\"\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
    "                            data[\"edge_index\"])\n",
    "    all_users = all_users_items[:len(data[\"users\"])]\n",
    "    items_emb = all_users_items[len(data[\"users\"]):]\n",
    "    users_emb = all_users[users.long()]\n",
    "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
    "    return rating\n",
    "\n",
    "def getEmbedding(model, users, pos, neg, data, mask):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    \"\"\"\n",
    "    # assuming we always search for users and items by their indices (instead of\n",
    "    # user/item number)\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
    "                            data[\"edge_index\"] * mask)\n",
    "    all_users = all_users_items[:len(data[\"users\"])]\n",
    "    all_items = all_users_items[len(data[\"users\"]):]\n",
    "    users_emb = all_users[users]\n",
    "    pos_emb = all_items[pos]\n",
    "    neg_emb = all_items[neg]\n",
    "    n_user = len(data[\"users\"])\n",
    "    users_emb_ego = model.embedding_user_item(users)\n",
    "    # offset the index to fetch embedding from user_item\n",
    "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
    "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
    "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7ct4L3DBnFh"
   },
   "source": [
    "## Bayesian Personalized Ranking loss (BPR loss)\n",
    "\n",
    "To train the LightGCN model, we need an objective function that aligns with our goal for movie recommendation. We use the Bayesian Personalized Ranking (BPR) loss, which encourages observed user-item predictions to have increasingly higher values than unobserved ones, along with $ L_2 $ regularization:\n",
    "$$ L_{BPR} = - \\sum_{u=1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) + \\lambda ||\\textbf{E}^{(0)} ||^2 $$\n",
    "where $ \\textbf{E}^{(0)} $ is a matrix with column vectors being the 0-th layer embeddings to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dZ62Sk46_uxB"
   },
   "outputs": [],
   "source": [
    "def bpr_loss(model, users, pos, neg, data, mask):\n",
    "    \"\"\" \n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "            (0-indexed, note to index items starting from 0)\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    OUTPUT:\n",
    "        loss, reg_loss\n",
    "    \"\"\"\n",
    "    # assuming we always sample the same number of positive and negative sample\n",
    "    # per user\n",
    "    assert len(users) == len(pos) and len(users) == len(neg)\n",
    "    (users_emb, pos_emb, neg_emb, \n",
    "    userEmb0,  posEmb0, negEmb0) = getEmbedding(model, users.long(), pos.long(),\n",
    "                                                neg.long(), data, mask)\n",
    "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + \n",
    "                        posEmb0.norm(2).pow(2)  +\n",
    "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
    "    pos_scores = torch.mul(users_emb, pos_emb)\n",
    "    pos_scores = torch.sum(pos_scores, dim=1)\n",
    "    neg_scores = torch.mul(users_emb, neg_emb)\n",
    "    neg_scores = torch.sum(neg_scores, dim=1)\n",
    "    \n",
    "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
    "    \n",
    "    return loss, reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eni-XlbOBydp"
   },
   "source": [
    "## Personalized top K precision and recall\n",
    "\n",
    "To evaluate training progress and model performance, we compute the **top K precision and recall** scores. Specifically, for each user, we rank movie items in order of decreasing similarity and choose the best K to recommend. Then, we compute the precision and recall of those K recommendations against ground truth items that the user likes and dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VjHb_Cr0_0gC"
   },
   "outputs": [],
   "source": [
    "def personalized_topk(pred, K, user_indices, edge_index):\n",
    "    \"\"\"Computes TopK precision and recall.\n",
    "\n",
    "    Args:\n",
    "        pred: Predicted similarities between user and item.\n",
    "        K: Number of items to rank.\n",
    "        user_indices: Indices of users for each prediction in `pred`.\n",
    "        edge_index: User and item connection matrix.\n",
    "\n",
    "    Returns:\n",
    "        Average Top K precision and recall for users in `user_indices`.\n",
    "    \"\"\"\n",
    "    \n",
    "    per_user_preds = collections.defaultdict(list)\n",
    "    for index, user in enumerate(user_indices):\n",
    "        per_user_preds[user.item()].append(pred[index].item())\n",
    "    \n",
    "    precisions = 0.0\n",
    "    recalls = 0.0\n",
    "    for user, preds in per_user_preds.items():\n",
    "        while len(preds) < K:\n",
    "            preds.append(random.choice(range(edge_index.shape[1])))\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
    "        correct_preds = edge_index[user, top_items].sum().item()\n",
    "        total_pos = edge_index[user].sum().item()\n",
    "        precisions += correct_preds / K\n",
    "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
    "    num_users = len(user_indices.unique())\n",
    "    return precisions / num_users, recalls / num_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VVAYXeFANXe"
   },
   "source": [
    "# Training, validation and testing\n",
    "\n",
    "Now, let's train our LightGCN model, and run it on the validation and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4VffTxqAkMY"
   },
   "source": [
    "## Sampling\n",
    "\n",
    "For each user, we randomly sample $n$ positive-negative movie examples and add them to the training, validation or test set. $n$ is a parameter that we can specify and tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qmAgY88nzzGm"
   },
   "outputs": [],
   "source": [
    "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples.\n",
    "    \"\"\"\n",
    "    print(\"=====Starting to sample=====\")\n",
    "    start = time.time()\n",
    "    samples = []\n",
    "    all_items = set(range(len(data[\"items\"])))\n",
    "    for user_index, user in enumerate(data[\"users\"]):\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        pos_items = set(\n",
    "            torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
    "        unknown_items = all_items.difference(\n",
    "                set(\n",
    "                    torch.nonzero(\n",
    "                        data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
    "        neg_items = all_items.difference(\n",
    "            set(pos_items)).difference(set(unknown_items))\n",
    "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
    "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
    "                len(unknown_items.union(neg_items)) == 0:\n",
    "            continue\n",
    "        for _ in range(num_samples_per_user):\n",
    "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(pos_items.intersection(unmasked_items)))\n",
    "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(neg_items.intersection(unmasked_items)))\n",
    "            samples.append((user_index, pos_item_index, neg_item_index))\n",
    "    end = time.time()\n",
    "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
    "    return torch.tensor(samples, dtype=torch.int32)\n",
    "\n",
    "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        train_mask: Masking matrix indicating edges present in train set.\n",
    "        val_mask: Masking matrix indicating edges present in validation set.\n",
    "        test_mask: Masking matrix indicating edges present in test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples for\n",
    "        train, validation and test.\n",
    "    \"\"\"\n",
    "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
    "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
    "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwxJ6gDMAmSF"
   },
   "source": [
    "## Training and validation\n",
    "\n",
    "Now, let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Users: 200\n",
      "#Items: 3883\n",
      "use NORMAL distribution initilizer\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 1.0242869853973389 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 0.9988396167755127 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 1.0005149841308594 seconds)=====\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "movielens = MovieLens(root=root, transform=trans_ml)\n",
    "data = movielens.get()\n",
    "train_mask, val_mask, test_mask = \\\n",
    "        movielens.train_val_test_split(val_frac=config_dict[\"val_frac\"],\n",
    "                                       test_frac=config_dict[\"test_frac\"])\n",
    "\n",
    "n_users = len(data[\"users\"].unique())\n",
    "m_items = len(data[\"items\"].unique())\n",
    "print(f\"#Users: {n_users}\")\n",
    "print(f\"#Items: {m_items}\")\n",
    "\n",
    "model_config = {\n",
    "    \"n_users\": n_users,\n",
    "    \"m_items\": m_items,\n",
    "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
    "    \"num_layers\": config_dict[\"num_layers\"],\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lightGCN = LightGCN(model_config, device=device)\n",
    "\n",
    "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
    "epochs = config_dict[\"epochs\"]\n",
    "batch_size = config_dict[\"batch_size\"]\n",
    "lr = config_dict[\"lr\"]\n",
    "weight_decay = config_dict[\"weight_decay\"]\n",
    "\n",
    "K = config_dict[\"K\"]\n",
    "\n",
    "lightGCN.to(device)\n",
    "\n",
    "samples_train, samples_val, samples_test = \\\n",
    "        sample_pos_neg(data, train_mask, val_mask, test_mask,\n",
    "                       num_samples_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 1267, 2086],\n",
      "        [   0,   47,   21],\n",
      "        [   0,  584,  558],\n",
      "        ...,\n",
      "        [ 199, 2530, 2701],\n",
      "        [ 199, 1111, 2637],\n",
      "        [ 199, 1111, 2701]], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1081, 1325],\n",
       "        [   0, 3045, 3718],\n",
       "        [   0,  148,  311],\n",
       "        ...,\n",
       "        [ 199, 3339, 2637],\n",
       "        [ 199, 3682, 2536],\n",
       "        [ 199, 2503, 2701]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_train.shape\n",
    "samples_val.shape\n",
    "print(samples_train)\n",
    "samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-NbgY1GzkR7",
    "outputId": "8cc0c651-0e5e-44bd-c496-038b0f54737e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Training samples: 100000 #Validation samples: 100000 #Test samples: 100000\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Training on the 0 epoch\n",
      "Training on epoch 0 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.703013, and regularization loss is 0.009866.\n",
      " Top K precision = 0.09473684210526312, recall = 0.006622160853450755.\n",
      "Training on epoch 0 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.699026, and regularization loss is 0.005879.\n",
      " Top K precision = 0.10454545454545451, recall = 0.009232577041090638.\n",
      "Training on epoch 0 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.697655, and regularization loss is 0.004508.\n",
      " Top K precision = 0.09677419354838705, recall = 0.007346948096965521.\n",
      "Training on epoch 0 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.696631, and regularization loss is 0.003484.\n",
      " Top K precision = 0.0826086956521739, recall = 0.007043425494001425.\n",
      "Training on epoch 0 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.695298, and regularization loss is 0.002151.\n",
      " Top K precision = 0.09032258064516127, recall = 0.006565793368308622.\n",
      "Training on epoch 0 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.694774, and regularization loss is 0.001627.\n",
      " Top K precision = 0.09891304347826083, recall = 0.008156991251675367.\n",
      "Training on epoch 0 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.6945, and regularization loss is 0.001353.\n",
      " Top K precision = 0.0858695652173913, recall = 0.0067673746084962174.\n",
      "Training on epoch 0 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.694013, and regularization loss is 0.000866.\n",
      " Top K precision = 0.09587628865979378, recall = 0.008654741510094602.\n",
      "\n",
      "Training on 0 epoch completed.\n",
      " Average bpr_loss on train set is 0.005445 for the current epoch.\n",
      " Training top K precision = 0.088, recall = 0.007462624504854294.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08149999999999993, recall = 0.007052120723137185.\n",
      "\n",
      "Training on the 1 epoch\n",
      "Training on epoch 1 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693972, and regularization loss is 0.000825.\n",
      " Top K precision = 0.0793478260869565, recall = 0.008108670832383227.\n",
      "Training on epoch 1 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.08613861386138612, recall = 0.006061297831228877.\n",
      "Training on epoch 1 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.07959183673469386, recall = 0.006500164973971471.\n",
      "Training on epoch 1 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.07395833333333333, recall = 0.006739731260343225.\n",
      "Training on epoch 1 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693885, and regularization loss is 0.000738.\n",
      " Top K precision = 0.08144329896907215, recall = 0.008523639444609382.\n",
      "Training on epoch 1 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693544, and regularization loss is 0.000396.\n",
      " Top K precision = 0.09450549450549449, recall = 0.00779278394479349.\n",
      "Training on epoch 1 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693515, and regularization loss is 0.000367.\n",
      " Top K precision = 0.08404255319148933, recall = 0.0076665586137238066.\n",
      "Training on epoch 1 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693636, and regularization loss is 0.000489.\n",
      " Top K precision = 0.07159090909090908, recall = 0.007233906329416307.\n",
      "\n",
      "Training on 1 epoch completed.\n",
      " Average bpr_loss on train set is 0.005425 for the current epoch.\n",
      " Training top K precision = 0.08649999999999995, recall = 0.007410879386312789.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.07399999999999995, recall = 0.005860180206023928.\n",
      "\n",
      "Training on the 2 epoch\n",
      "Training on epoch 2 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693561, and regularization loss is 0.000414.\n",
      " Top K precision = 0.10217391304347824, recall = 0.00753342731507703.\n",
      "Training on epoch 2 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693426, and regularization loss is 0.000279.\n",
      " Top K precision = 0.07755102040816324, recall = 0.006759086715967632.\n",
      "Training on epoch 2 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.08723404255319146, recall = 0.007542108291017326.\n",
      "Training on epoch 2 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693368, and regularization loss is 0.000221.\n",
      " Top K precision = 0.09587628865979377, recall = 0.008505067698412819.\n",
      "Training on epoch 2 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693502, and regularization loss is 0.000355.\n",
      " Top K precision = 0.08217821782178213, recall = 0.00806255476196251.\n",
      "Training on epoch 2 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693304, and regularization loss is 0.000157.\n",
      " Top K precision = 0.09368421052631576, recall = 0.006706065234166748.\n",
      "Training on epoch 2 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693385, and regularization loss is 0.000238.\n",
      " Top K precision = 0.09780219780219777, recall = 0.007359276780266356.\n",
      "Training on epoch 2 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693345, and regularization loss is 0.000198.\n",
      " Top K precision = 0.08936170212765954, recall = 0.008926815281579856.\n",
      "\n",
      "Training on 2 epoch completed.\n",
      " Average bpr_loss on train set is 0.005422 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 3 epoch\n",
      "Training on epoch 3 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693294, and regularization loss is 0.000146.\n",
      " Top K precision = 0.07419354838709677, recall = 0.005373935212848552.\n",
      "Training on epoch 3 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693318, and regularization loss is 0.000171.\n",
      " Top K precision = 0.07878787878787877, recall = 0.005730653584045544.\n",
      "Training on epoch 3 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693292, and regularization loss is 0.000144.\n",
      " Top K precision = 0.10322580645161286, recall = 0.008568011226346988.\n",
      "Training on epoch 3 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693192, and regularization loss is 4.4e-05.\n",
      " Top K precision = 0.07731958762886597, recall = 0.006511690514306241.\n",
      "Training on epoch 3 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693178, and regularization loss is 3.1e-05.\n",
      " Top K precision = 0.0948979591836734, recall = 0.007091418450263817.\n",
      "Training on epoch 3 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693399, and regularization loss is 0.000252.\n",
      " Top K precision = 0.08399999999999996, recall = 0.006389913091634377.\n",
      "Training on epoch 3 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693302, and regularization loss is 0.000155.\n",
      " Top K precision = 0.11538461538461535, recall = 0.009019315432847187.\n",
      "Training on epoch 3 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693513, and regularization loss is 0.000365.\n",
      " Top K precision = 0.0880434782608695, recall = 0.007983621158449585.\n",
      "\n",
      "Training on 3 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 4 epoch\n",
      "Training on epoch 4 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693184, and regularization loss is 3.7e-05.\n",
      " Top K precision = 0.095049504950495, recall = 0.008756384273443185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 4 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693282, and regularization loss is 0.000135.\n",
      " Top K precision = 0.08799999999999997, recall = 0.006056492361296939.\n",
      "Training on epoch 4 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693185, and regularization loss is 3.7e-05.\n",
      " Top K precision = 0.08817204301075268, recall = 0.008453965074255044.\n",
      "Training on epoch 4 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693222, and regularization loss is 7.4e-05.\n",
      " Top K precision = 0.07659574468085105, recall = 0.006554096761842497.\n",
      "Training on epoch 4 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693351, and regularization loss is 0.000204.\n",
      " Top K precision = 0.07204301075268814, recall = 0.006902981185102445.\n",
      "Training on epoch 4 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10109890109890106, recall = 0.008104736317440202.\n",
      "Training on epoch 4 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693232, and regularization loss is 8.5e-05.\n",
      " Top K precision = 0.08247422680412368, recall = 0.007962181752042191.\n",
      "Training on epoch 4 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693204, and regularization loss is 5.7e-05.\n",
      " Top K precision = 0.09247311827956985, recall = 0.008859183514121438.\n",
      "\n",
      "Training on 4 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999995, recall = 0.007440503750836979.\n",
      "\n",
      "Training on the 5 epoch\n",
      "Training on epoch 5 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693186, and regularization loss is 3.8e-05.\n",
      " Top K precision = 0.08139534883720931, recall = 0.006591926581020451.\n",
      "Training on epoch 5 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.11333333333333329, recall = 0.008208923310833956.\n",
      "Training on epoch 5 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693193, and regularization loss is 4.5e-05.\n",
      " Top K precision = 0.09484536082474222, recall = 0.008460882861190122.\n",
      "Training on epoch 5 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.09888888888888886, recall = 0.009020161077409177.\n",
      "Training on epoch 5 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693198, and regularization loss is 5.1e-05.\n",
      " Top K precision = 0.09793814432989689, recall = 0.007499841565956453.\n",
      "Training on epoch 5 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693199, and regularization loss is 5.1e-05.\n",
      " Top K precision = 0.0938144329896907, recall = 0.006798911395713381.\n",
      "Training on epoch 5 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693191, and regularization loss is 4.3e-05.\n",
      " Top K precision = 0.09009900990099005, recall = 0.007160700292162007.\n",
      "Training on epoch 5 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.10106382978723398, recall = 0.007948997414511447.\n",
      "\n",
      "Training on 5 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474773.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 6 epoch\n",
      "Training on epoch 6 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0789473684210526, recall = 0.006941918268915658.\n",
      "Training on epoch 6 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09361702127659571, recall = 0.007899804678688407.\n",
      "Training on epoch 6 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693188, and regularization loss is 4.1e-05.\n",
      " Top K precision = 0.0864583333333333, recall = 0.007762679296119976.\n",
      "Training on epoch 6 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09052631578947368, recall = 0.005885691313842997.\n",
      "Training on epoch 6 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.08842105263157891, recall = 0.007024787396609273.\n",
      "Training on epoch 6 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693187, and regularization loss is 4e-05.\n",
      " Top K precision = 0.08061224489795915, recall = 0.006390287903095377.\n",
      "Training on epoch 6 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.07999999999999997, recall = 0.007216870403725929.\n",
      "Training on epoch 6 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08787878787878785, recall = 0.006560503178479025.\n",
      "\n",
      "Training on 6 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 7 epoch\n",
      "Training on epoch 7 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693185, and regularization loss is 3.7e-05.\n",
      " Top K precision = 0.07634408602150537, recall = 0.007480199724615907.\n",
      "Training on epoch 7 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
      " Top K precision = 0.09099999999999998, recall = 0.0073950596136847365.\n",
      "Training on epoch 7 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08058252427184463, recall = 0.007900331138861886.\n",
      "Training on epoch 7 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.11145833333333321, recall = 0.008313585864546974.\n",
      "Training on epoch 7 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09789473684210526, recall = 0.007730323992935458.\n",
      "Training on epoch 7 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08019801980198016, recall = 0.006862564563921981.\n",
      "Training on epoch 7 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09462365591397845, recall = 0.008135770161261307.\n",
      "Training on epoch 7 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693193, and regularization loss is 4.6e-05.\n",
      " Top K precision = 0.08314606741573032, recall = 0.008073444829517494.\n",
      "\n",
      "Training on 7 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999994, recall = 0.007488349592263509.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 8 epoch\n",
      "Training on epoch 8 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08854166666666662, recall = 0.008022875719784215.\n",
      "Training on epoch 8 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10326086956521734, recall = 0.0089996782673368.\n",
      "Training on epoch 8 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0908045977011494, recall = 0.007523865419859653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 8 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09166666666666666, recall = 0.007634314996538191.\n",
      "Training on epoch 8 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08659793814432988, recall = 0.007183716199190438.\n",
      "Training on epoch 8 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08191489361702126, recall = 0.0074712088224820625.\n",
      "Training on epoch 8 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08723404255319146, recall = 0.007443599937360735.\n",
      "Training on epoch 8 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10769230769230768, recall = 0.009900293095001855.\n",
      "\n",
      "Training on 8 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08900000000000002, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 9 epoch\n",
      "Training on epoch 9 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.6932, and regularization loss is 5.2e-05.\n",
      " Top K precision = 0.09021739130434779, recall = 0.007926750209607017.\n",
      "Training on epoch 9 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.0870588235294117, recall = 0.00830849052641674.\n",
      "Training on epoch 9 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09587628865979372, recall = 0.008375073943356848.\n",
      "Training on epoch 9 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0857142857142857, recall = 0.008102878029044889.\n",
      "Training on epoch 9 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07422680412371133, recall = 0.006367536159088573.\n",
      "Training on epoch 9 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09591836734693875, recall = 0.006688134293859291.\n",
      "Training on epoch 9 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.09157894736842102, recall = 0.0066328072557365015.\n",
      "Training on epoch 9 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09270833333333328, recall = 0.007588808166627895.\n",
      "\n",
      "Training on 9 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 10 epoch\n",
      "Training on epoch 10 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09578947368421047, recall = 0.008498133213253876.\n",
      "Training on epoch 10 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09595959595959587, recall = 0.007491938300073058.\n",
      "Training on epoch 10 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08124999999999993, recall = 0.007655196290459561.\n",
      "Training on epoch 10 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09166666666666666, recall = 0.008440814540789031.\n",
      "Training on epoch 10 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08399999999999996, recall = 0.00713620017593495.\n",
      "Training on epoch 10 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08723404255319146, recall = 0.007070696522249701.\n",
      "Training on epoch 10 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09361702127659571, recall = 0.006980032023804233.\n",
      "Training on epoch 10 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07934782608695652, recall = 0.005708218510226778.\n",
      "\n",
      "Training on 10 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 11 epoch\n",
      "Training on epoch 11 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08932038834951452, recall = 0.007412740604685717.\n",
      "Training on epoch 11 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
      " Top K precision = 0.0776595744680851, recall = 0.008296178227190996.\n",
      "Training on epoch 11 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09120879120879118, recall = 0.006603253917700176.\n",
      "Training on epoch 11 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09680851063829782, recall = 0.008909444738530612.\n",
      "Training on epoch 11 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08631578947368418, recall = 0.007057442370509645.\n",
      "Training on epoch 11 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08762886597938141, recall = 0.008297799913762798.\n",
      "Training on epoch 11 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08089887640449436, recall = 0.004734722856245652.\n",
      "Training on epoch 11 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08829787234042552, recall = 0.007535436660543135.\n",
      "\n",
      "Training on 11 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08999999999999994, recall = 0.007624131604598957.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 12 epoch\n",
      "Training on epoch 12 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09139784946236554, recall = 0.007380636187650531.\n",
      "Training on epoch 12 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09099999999999996, recall = 0.00842193454872818.\n",
      "Training on epoch 12 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10666666666666665, recall = 0.008612442058228078.\n",
      "Training on epoch 12 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0852631578947368, recall = 0.00818452138252555.\n",
      "Training on epoch 12 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10206185567010308, recall = 0.009663259215879839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 12 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08260869565217391, recall = 0.008388108106415682.\n",
      "Training on epoch 12 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0757894736842105, recall = 0.007556247086686755.\n",
      "Training on epoch 12 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10434782608695646, recall = 0.009106542033122372.\n",
      "\n",
      "Training on 12 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 13 epoch\n",
      "Training on epoch 13 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09139784946236557, recall = 0.0080385577804761.\n",
      "Training on epoch 13 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09399999999999999, recall = 0.00652177318646311.\n",
      "Training on epoch 13 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08921568627450976, recall = 0.007741767243419572.\n",
      "Training on epoch 13 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10399999999999993, recall = 0.009116177164299516.\n",
      "Training on epoch 13 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09670329670329668, recall = 0.0070526065663370835.\n",
      "Training on epoch 13 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08666666666666667, recall = 0.007546826682555255.\n",
      "Training on epoch 13 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.09484536082474222, recall = 0.008399555667182564.\n",
      "Training on epoch 13 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08539325842696628, recall = 0.0073580164215668094.\n",
      "\n",
      "Training on 13 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 14 epoch\n",
      "Training on epoch 14 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09680851063829783, recall = 0.00845150093913279.\n",
      "Training on epoch 14 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07894736842105261, recall = 0.008600740461940969.\n",
      "Training on epoch 14 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07676767676767673, recall = 0.005895444057752226.\n",
      "Training on epoch 14 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08541666666666664, recall = 0.007057368503784897.\n",
      "Training on epoch 14 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09787234042553185, recall = 0.008677345118120442.\n",
      "Training on epoch 14 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09999999999999994, recall = 0.008507345918003607.\n",
      "Training on epoch 14 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08602150537634409, recall = 0.008247946271198037.\n",
      "Training on epoch 14 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07894736842105261, recall = 0.006264093346153865.\n",
      "\n",
      "Training on 14 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 15 epoch\n",
      "Training on epoch 15 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07722772277227721, recall = 0.008077735606486287.\n",
      "Training on epoch 15 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.0833333333333333, recall = 0.006953074408656693.\n",
      "Training on epoch 15 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09052631578947366, recall = 0.008519354366110576.\n",
      "Training on epoch 15 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0896907216494845, recall = 0.008243596163267836.\n",
      "Training on epoch 15 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08514851485148511, recall = 0.006596861752043335.\n",
      "Training on epoch 15 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07857142857142854, recall = 0.007800392069464072.\n",
      "Training on epoch 15 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.0833333333333333, recall = 0.006549863271024698.\n",
      "Training on epoch 15 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07938144329896904, recall = 0.007577305178556991.\n",
      "\n",
      "Training on 15 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999995, recall = 0.007705830951004188.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075790150424545335.\n",
      "\n",
      "Training on the 16 epoch\n",
      "Training on epoch 16 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09782608695652176, recall = 0.006182648322750679.\n",
      "Training on epoch 16 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.09897959183673465, recall = 0.009273568952475398.\n",
      "Training on epoch 16 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09560439560439558, recall = 0.007600990316384338.\n",
      "Training on epoch 16 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08823529411764702, recall = 0.006401872753523873.\n",
      "Training on epoch 16 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08709677419354836, recall = 0.006157508466513164.\n",
      "Training on epoch 16 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08315789473684207, recall = 0.008432366197063246.\n",
      "Training on epoch 16 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09999999999999998, recall = 0.008239964035645973.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 16 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09468085106382977, recall = 0.008255686539930678.\n",
      "\n",
      "Training on 16 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 17 epoch\n",
      "Training on epoch 17 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09899999999999995, recall = 0.009483432772655984.\n",
      "Training on epoch 17 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08478260869565214, recall = 0.007009038600014567.\n",
      "Training on epoch 17 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09263157894736841, recall = 0.008203730406896958.\n",
      "Training on epoch 17 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08764044943820222, recall = 0.0069148398973302196.\n",
      "Training on epoch 17 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09139784946236557, recall = 0.00799485170429507.\n",
      "Training on epoch 17 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.07356321839080458, recall = 0.0066344481964902054.\n",
      "Training on epoch 17 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08791208791208789, recall = 0.00851456381719747.\n",
      "Training on epoch 17 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0882978723404255, recall = 0.008596936688453597.\n",
      "\n",
      "Training on 17 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 18 epoch\n",
      "Training on epoch 18 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08499999999999998, recall = 0.006702202991170299.\n",
      "Training on epoch 18 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08787878787878783, recall = 0.0077785657045826555.\n",
      "Training on epoch 18 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09789473684210523, recall = 0.008255356650135309.\n",
      "Training on epoch 18 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08854166666666667, recall = 0.006324561452314536.\n",
      "Training on epoch 18 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07872340425531911, recall = 0.007867803658668859.\n",
      "Training on epoch 18 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08865979381443292, recall = 0.007838759623736976.\n",
      "Training on epoch 18 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09263157894736841, recall = 0.008629939915209791.\n",
      "Training on epoch 18 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09499999999999999, recall = 0.008710915358227992.\n",
      "\n",
      "Training on 18 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 19 epoch\n",
      "Training on epoch 19 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.10531914893617016, recall = 0.007291201368609181.\n",
      "Training on epoch 19 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08829787234042552, recall = 0.00825240647247933.\n",
      "Training on epoch 19 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.0979166666666666, recall = 0.009087039862969956.\n",
      "Training on epoch 19 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.0934065934065934, recall = 0.00750243015287865.\n",
      "Training on epoch 19 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08817204301075268, recall = 0.009030784391894413.\n",
      "Training on epoch 19 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07999999999999999, recall = 0.006998514910302118.\n",
      "Training on epoch 19 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08586956521739127, recall = 0.008434126891386111.\n",
      "Training on epoch 19 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09690721649484535, recall = 0.008887676412318714.\n",
      "\n",
      "Training on 19 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 20 epoch\n",
      "Training on epoch 20 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09393939393939388, recall = 0.007407730407256838.\n",
      "Training on epoch 20 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09278350515463914, recall = 0.008219477080138097.\n",
      "Training on epoch 20 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08936170212765952, recall = 0.007730657416851639.\n",
      "Training on epoch 20 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07789473684210525, recall = 0.007483691438332385.\n",
      "Training on epoch 20 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09651162790697673, recall = 0.008182492071623639.\n",
      "Training on epoch 20 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07872340425531914, recall = 0.006785492719298497.\n",
      "Training on epoch 20 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09139784946236554, recall = 0.008923170968876173.\n",
      "Training on epoch 20 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08736842105263155, recall = 0.00756760935722546.\n",
      "\n",
      "Training on 20 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007492982653790564.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 21 epoch\n",
      "Training on epoch 21 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09222222222222218, recall = 0.008458793671378837.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 21 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09791666666666664, recall = 0.00865465141980592.\n",
      "Training on epoch 21 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07999999999999997, recall = 0.006462486702526279.\n",
      "Training on epoch 21 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09361702127659573, recall = 0.00764505758632801.\n",
      "Training on epoch 21 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09687499999999993, recall = 0.00822446625677634.\n",
      "Training on epoch 21 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.10104166666666663, recall = 0.008085859285817636.\n",
      "Training on epoch 21 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.006190083827183164.\n",
      "Training on epoch 21 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07978723404255318, recall = 0.006516739436157845.\n",
      "\n",
      "Training on 21 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 22 epoch\n",
      "Training on epoch 22 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09175257731958758, recall = 0.009065881828233566.\n",
      "Training on epoch 22 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08181818181818178, recall = 0.006545328160149729.\n",
      "Training on epoch 22 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09684210526315781, recall = 0.006667860787511107.\n",
      "Training on epoch 22 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08666666666666664, recall = 0.0073240978663911905.\n",
      "Training on epoch 22 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09354838709677414, recall = 0.007783589075176241.\n",
      "Training on epoch 22 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08369565217391303, recall = 0.006302739915670585.\n",
      "Training on epoch 22 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09292929292929286, recall = 0.00628105101369827.\n",
      "Training on epoch 22 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.11010101010101005, recall = 0.008023703779471739.\n",
      "\n",
      "Training on 22 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999994, recall = 0.007468239394228471.\n",
      "\n",
      "Training on the 23 epoch\n",
      "Training on epoch 23 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10599999999999996, recall = 0.008191393634121562.\n",
      "Training on epoch 23 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08681318681318678, recall = 0.006343060723599307.\n",
      "Training on epoch 23 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09578947368421051, recall = 0.008057023567522454.\n",
      "Training on epoch 23 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08969072164948452, recall = 0.007051949010728007.\n",
      "Training on epoch 23 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.08709677419354836, recall = 0.007644016343779257.\n",
      "Training on epoch 23 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08315789473684206, recall = 0.006768742601019162.\n",
      "Training on epoch 23 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08842105263157891, recall = 0.00741232998895175.\n",
      "Training on epoch 23 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09021739130434782, recall = 0.008463661227005486.\n",
      "\n",
      "Training on 23 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 24 epoch\n",
      "Training on epoch 24 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09387755102040814, recall = 0.00711971873207036.\n",
      "Training on epoch 24 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08199999999999998, recall = 0.00726083883802377.\n",
      "Training on epoch 24 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08842105263157897, recall = 0.009630341663829525.\n",
      "Training on epoch 24 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.08222222222222221, recall = 0.00676304367873887.\n",
      "Training on epoch 24 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08817204301075267, recall = 0.006574795062779198.\n",
      "Training on epoch 24 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07872340425531915, recall = 0.008589686040856779.\n",
      "Training on epoch 24 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.10499999999999997, recall = 0.007316753796840742.\n",
      "Training on epoch 24 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0908163265306122, recall = 0.007707641338763057.\n",
      "\n",
      "Training on 24 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 25 epoch\n",
      "Training on epoch 25 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08556701030927834, recall = 0.006770862074717966.\n",
      "Training on epoch 25 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08699999999999995, recall = 0.006327005699341692.\n",
      "Training on epoch 25 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08811881188118809, recall = 0.008282858372005734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 25 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09255319148936164, recall = 0.0075058906688527365.\n",
      "Training on epoch 25 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10210526315789469, recall = 0.0071636578258646695.\n",
      "Training on epoch 25 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09325842696629208, recall = 0.008138006533484525.\n",
      "Training on epoch 25 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07938144329896905, recall = 0.008208575324582041.\n",
      "Training on epoch 25 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09247311827956987, recall = 0.0067526243072783725.\n",
      "\n",
      "Training on 25 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474781.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 26 epoch\n",
      "Training on epoch 26 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0791208791208791, recall = 0.008899367623996743.\n",
      "Training on epoch 26 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08369565217391306, recall = 0.008079061820907733.\n",
      "Training on epoch 26 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0702127659574468, recall = 0.007145843119959009.\n",
      "Training on epoch 26 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07499999999999997, recall = 0.005814430484003899.\n",
      "Training on epoch 26 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09239130434782605, recall = 0.007172469718951008.\n",
      "Training on epoch 26 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07916666666666666, recall = 0.006950576250202657.\n",
      "Training on epoch 26 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08453608247422678, recall = 0.0061682061163554625.\n",
      "Training on epoch 26 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09784946236559136, recall = 0.00789819244205107.\n",
      "\n",
      "Training on 26 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08800000000000002, recall = 0.007534322249724164.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999997, recall = 0.007456858190532209.\n",
      "\n",
      "Training on the 27 epoch\n",
      "Training on epoch 27 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09890109890109887, recall = 0.009755886168602438.\n",
      "Training on epoch 27 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08229166666666667, recall = 0.008405668003076863.\n",
      "Training on epoch 27 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.09523809523809519, recall = 0.008370758503553358.\n",
      "Training on epoch 27 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08199999999999998, recall = 0.005674835995076693.\n",
      "Training on epoch 27 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07291666666666664, recall = 0.006954118000588482.\n",
      "Training on epoch 27 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08064516129032258, recall = 0.005830643728988747.\n",
      "Training on epoch 27 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09130434782608694, recall = 0.007892320774437722.\n",
      "Training on epoch 27 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.00888376425042357.\n",
      "\n",
      "Training on 27 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 28 epoch\n",
      "Training on epoch 28 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08181818181818182, recall = 0.007431164848266133.\n",
      "Training on epoch 28 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08571428571428569, recall = 0.00722917790391361.\n",
      "Training on epoch 28 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.08279569892473117, recall = 0.007518415073862819.\n",
      "Training on epoch 28 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09555555555555555, recall = 0.008057020245331952.\n",
      "Training on epoch 28 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08977272727272725, recall = 0.007693391483172728.\n",
      "Training on epoch 28 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0943181818181818, recall = 0.00789454423367031.\n",
      "Training on epoch 28 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08913043478260867, recall = 0.008188938939170318.\n",
      "Training on epoch 28 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693181, and regularization loss is 3.3e-05.\n",
      " Top K precision = 0.10105263157894732, recall = 0.007027113842762886.\n",
      "\n",
      "Training on 28 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 29 epoch\n",
      "Training on epoch 29 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09591836734693872, recall = 0.007258747446658249.\n",
      "Training on epoch 29 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07604166666666662, recall = 0.00676858101910134.\n",
      "Training on epoch 29 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.091, recall = 0.008824776833805793.\n",
      "Training on epoch 29 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08064516129032259, recall = 0.008201809697993999.\n",
      "Training on epoch 29 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0879120879120879, recall = 0.006880119813275221.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 29 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.075531914893617, recall = 0.006216628963096424.\n",
      "Training on epoch 29 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09361702127659571, recall = 0.008229738217842642.\n",
      "Training on epoch 29 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09148936170212761, recall = 0.007705118049690423.\n",
      "\n",
      "Training on 29 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 30 epoch\n",
      "Training on epoch 30 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08837209302325576, recall = 0.006343551375038548.\n",
      "Training on epoch 30 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0842696629213483, recall = 0.005735525397234379.\n",
      "Training on epoch 30 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08947368421052625, recall = 0.008216813218401326.\n",
      "Training on epoch 30 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09069767441860464, recall = 0.006367872417217488.\n",
      "Training on epoch 30 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09062499999999996, recall = 0.007455076866448892.\n",
      "Training on epoch 30 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.09473684210526316, recall = 0.009687288338689454.\n",
      "Training on epoch 30 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09052631578947365, recall = 0.00773935173311485.\n",
      "Training on epoch 30 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09199999999999994, recall = 0.007293945490649133.\n",
      "\n",
      "Training on 30 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 31 epoch\n",
      "Training on epoch 31 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09134615384615376, recall = 0.00829523925953714.\n",
      "Training on epoch 31 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08315789473684208, recall = 0.007407669304227354.\n",
      "Training on epoch 31 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.0895833333333333, recall = 0.00743633515263688.\n",
      "Training on epoch 31 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08585858585858584, recall = 0.006922599770665943.\n",
      "Training on epoch 31 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08910891089108909, recall = 0.007448142587083678.\n",
      "Training on epoch 31 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0855670103092783, recall = 0.007281307417928966.\n",
      "Training on epoch 31 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09361702127659573, recall = 0.007479390269020701.\n",
      "Training on epoch 31 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09677419354838705, recall = 0.008330958592216628.\n",
      "\n",
      "Training on 31 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999997, recall = 0.007456858190532209.\n",
      "\n",
      "Training on the 32 epoch\n",
      "Training on epoch 32 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09009900990099008, recall = 0.006101607993463073.\n",
      "Training on epoch 32 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08163265306122446, recall = 0.006519273515138457.\n",
      "Training on epoch 32 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09374999999999996, recall = 0.007784819331844848.\n",
      "Training on epoch 32 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07777777777777779, recall = 0.00619655012270683.\n",
      "Training on epoch 32 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0845360824742268, recall = 0.00745854282430332.\n",
      "Training on epoch 32 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08131868131868131, recall = 0.006228586302776709.\n",
      "Training on epoch 32 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07676767676767675, recall = 0.00804858830939453.\n",
      "Training on epoch 32 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10645161290322577, recall = 0.00724629496700441.\n",
      "\n",
      "Training on 32 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 33 epoch\n",
      "Training on epoch 33 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07216494845360821, recall = 0.007014355242282103.\n",
      "Training on epoch 33 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08804347826086954, recall = 0.007162392647188564.\n",
      "Training on epoch 33 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07731958762886594, recall = 0.007547743283691996.\n",
      "Training on epoch 33 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0683673469387755, recall = 0.0058301345233118035.\n",
      "Training on epoch 33 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08111111111111108, recall = 0.007706177124833879.\n",
      "Training on epoch 33 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10721649484536074, recall = 0.008427005225530403.\n",
      "Training on epoch 33 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09891304347826083, recall = 0.008169886433283946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 33 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07373737373737371, recall = 0.006872872070922403.\n",
      "\n",
      "Training on 33 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999995, recall = 0.007440503750836979.\n",
      "\n",
      "Training on the 34 epoch\n",
      "Training on epoch 34 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09374999999999999, recall = 0.008565703157811449.\n",
      "Training on epoch 34 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.083695652173913, recall = 0.007755511331245152.\n",
      "Training on epoch 34 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0923076923076923, recall = 0.0076054363432723525.\n",
      "Training on epoch 34 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10303030303030303, recall = 0.00901662253814738.\n",
      "Training on epoch 34 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08367346938775509, recall = 0.007358678787460216.\n",
      "Training on epoch 34 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08505747126436781, recall = 0.005523696895729714.\n",
      "Training on epoch 34 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09784946236559136, recall = 0.00744723132193948.\n",
      "Training on epoch 34 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10105263157894732, recall = 0.007560321575179092.\n",
      "\n",
      "Training on 34 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999995, recall = 0.007567606049736262.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 35 epoch\n",
      "Training on epoch 35 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08846153846153845, recall = 0.007266492922764458.\n",
      "Training on epoch 35 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09021739130434782, recall = 0.007582259571013059.\n",
      "Training on epoch 35 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07604166666666663, recall = 0.006665783552770963.\n",
      "Training on epoch 35 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0913043478260869, recall = 0.007873445364775855.\n",
      "Training on epoch 35 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08383838383838382, recall = 0.007784133994569947.\n",
      "Training on epoch 35 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.08350515463917521, recall = 0.007545462952949896.\n",
      "Training on epoch 35 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08421052631578943, recall = 0.006871631579425573.\n",
      "Training on epoch 35 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.0848484848484848, recall = 0.006345120498772776.\n",
      "\n",
      "Training on 35 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08849999999999997, recall = 0.007492982653790566.\n",
      "\n",
      "Training on the 36 epoch\n",
      "Training on epoch 36 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69318, and regularization loss is 3.2e-05.\n",
      " Top K precision = 0.08437499999999998, recall = 0.006981291734107363.\n",
      "Training on epoch 36 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.0927835051546391, recall = 0.009147751935613527.\n",
      "Training on epoch 36 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09117647058823526, recall = 0.007142926539231671.\n",
      "Training on epoch 36 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.0775280898876404, recall = 0.0068791923837388394.\n",
      "Training on epoch 36 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07499999999999997, recall = 0.008183193159978588.\n",
      "Training on epoch 36 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0912087912087912, recall = 0.008377864471750615.\n",
      "Training on epoch 36 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09239130434782605, recall = 0.0072639401429568.\n",
      "Training on epoch 36 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10105263157894732, recall = 0.009215024278753037.\n",
      "\n",
      "Training on 36 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08900000000000001, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 37 epoch\n",
      "Training on epoch 37 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.10454545454545451, recall = 0.00885780176459452.\n",
      "Training on epoch 37 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09157894736842102, recall = 0.00853822241254881.\n",
      "Training on epoch 37 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09680851063829783, recall = 0.007294288829738087.\n",
      "Training on epoch 37 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08299999999999998, recall = 0.006111987077398009.\n",
      "Training on epoch 37 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09684210526315787, recall = 0.00858007695129291.\n",
      "Training on epoch 37 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08932038834951449, recall = 0.006531750099455587.\n",
      "Training on epoch 37 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08494623655913978, recall = 0.007146415050464522.\n",
      "Training on epoch 37 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08999999999999998, recall = 0.007403125062850686.\n",
      "\n",
      "Training on 37 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 38 epoch\n",
      "Training on epoch 38 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09207920792079205, recall = 0.007876525704934493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 38 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09320388349514558, recall = 0.008096618755736177.\n",
      "Training on epoch 38 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09615384615384612, recall = 0.007236957430807804.\n",
      "Training on epoch 38 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0887755102040816, recall = 0.00790357562251553.\n",
      "Training on epoch 38 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.1, recall = 0.007531156227501763.\n",
      "Training on epoch 38 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09374999999999996, recall = 0.007313245390443747.\n",
      "Training on epoch 38 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08901098901098901, recall = 0.0062257345164149856.\n",
      "Training on epoch 38 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07362637362637361, recall = 0.006877489131907868.\n",
      "\n",
      "Training on 38 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08849999999999993, recall = 0.007477745097650524.\n",
      "\n",
      "Training on the 39 epoch\n",
      "Training on epoch 39 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08749999999999997, recall = 0.007473844842826102.\n",
      "Training on epoch 39 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08172043010752687, recall = 0.006324085395674557.\n",
      "Training on epoch 39 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08863636363636365, recall = 0.006825613382726665.\n",
      "Training on epoch 39 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10206185567010302, recall = 0.006475584973308118.\n",
      "Training on epoch 39 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08602150537634405, recall = 0.006997897018463673.\n",
      "Training on epoch 39 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08988764044943814, recall = 0.0078985600494037.\n",
      "Training on epoch 39 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.10978260869565211, recall = 0.008769025371017125.\n",
      "Training on epoch 39 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08936170212765954, recall = 0.007960462239054687.\n",
      "\n",
      "Training on 39 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08900000000000001, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08999999999999997, recall = 0.007588520745876587.\n",
      "\n",
      "Training on the 40 epoch\n",
      "Training on epoch 40 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08777777777777775, recall = 0.009254610945253941.\n",
      "Training on epoch 40 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0789473684210526, recall = 0.0056857762652934695.\n",
      "Training on epoch 40 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09278350515463914, recall = 0.006971508362453965.\n",
      "Training on epoch 40 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07525773195876286, recall = 0.007345477109055249.\n",
      "Training on epoch 40 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09999999999999995, recall = 0.008558020943955108.\n",
      "Training on epoch 40 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08160919540229881, recall = 0.006228105382688798.\n",
      "Training on epoch 40 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07717391304347823, recall = 0.007840827520586485.\n",
      "Training on epoch 40 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 7e-06.\n",
      " Top K precision = 0.09072164948453607, recall = 0.008526191828970079.\n",
      "\n",
      "Training on 40 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007445135763838412.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 41 epoch\n",
      "Training on epoch 41 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.08695652173913039, recall = 0.0077410565442125046.\n",
      "Training on epoch 41 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09784946236559137, recall = 0.0078089557722382736.\n",
      "Training on epoch 41 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.06989247311827954, recall = 0.007392882279517992.\n",
      "Training on epoch 41 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08936170212765956, recall = 0.007722533303533821.\n",
      "Training on epoch 41 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09361702127659571, recall = 0.007120855775002091.\n",
      "Training on epoch 41 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08064516129032255, recall = 0.007544846949005434.\n",
      "Training on epoch 41 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08111111111111106, recall = 0.007319641017414306.\n",
      "Training on epoch 41 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08315789473684207, recall = 0.005945799655020033.\n",
      "\n",
      "Training on 41 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08849999999999997, recall = 0.0075438279531462185.\n",
      "\n",
      "Training on the 42 epoch\n",
      "Training on epoch 42 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08749999999999997, recall = 0.006609148319926252.\n",
      "Training on epoch 42 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07252747252747248, recall = 0.007781350240878955.\n",
      "Training on epoch 42 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09399999999999993, recall = 0.00828705651713701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 42 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07878787878787877, recall = 0.005656972569192551.\n",
      "Training on epoch 42 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08453608247422678, recall = 0.005811155574636571.\n",
      "Training on epoch 42 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09999999999999998, recall = 0.008271233119932142.\n",
      "Training on epoch 42 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08, recall = 0.006355032217055613.\n",
      "Training on epoch 42 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08585858585858584, recall = 0.008202675879682347.\n",
      "\n",
      "Training on 42 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 43 epoch\n",
      "Training on epoch 43 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08936170212765952, recall = 0.007719637879163581.\n",
      "Training on epoch 43 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09696969696969691, recall = 0.007883574744667401.\n",
      "Training on epoch 43 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08172043010752683, recall = 0.007811413134317033.\n",
      "Training on epoch 43 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.10306122448979589, recall = 0.008270010780165689.\n",
      "Training on epoch 43 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09299999999999996, recall = 0.007592986769885358.\n",
      "Training on epoch 43 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.09574468085106379, recall = 0.007632175084414749.\n",
      "Training on epoch 43 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08842105263157891, recall = 0.0070616796958601884.\n",
      "Training on epoch 43 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0835164835164835, recall = 0.006872671440544285.\n",
      "\n",
      "Training on 43 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 44 epoch\n",
      "Training on epoch 44 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0936170212765957, recall = 0.008169927717672379.\n",
      "Training on epoch 44 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08241758241758237, recall = 0.006029484334818145.\n",
      "Training on epoch 44 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07640449438202244, recall = 0.00647827550884941.\n",
      "Training on epoch 44 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07526881720430106, recall = 0.006946759645945073.\n",
      "Training on epoch 44 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08842105263157893, recall = 0.006887542585547461.\n",
      "Training on epoch 44 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09425287356321836, recall = 0.009020464239865411.\n",
      "Training on epoch 44 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08315789473684208, recall = 0.008293415908896323.\n",
      "Training on epoch 44 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0677083333333333, recall = 0.008223039554526758.\n",
      "\n",
      "Training on 44 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 45 epoch\n",
      "Training on epoch 45 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.0793478260869565, recall = 0.007846112115610888.\n",
      "Training on epoch 45 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10106382978723401, recall = 0.009320636201768002.\n",
      "Training on epoch 45 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09999999999999998, recall = 0.008788749985360429.\n",
      "Training on epoch 45 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09772727272727268, recall = 0.007856153845251129.\n",
      "Training on epoch 45 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09687499999999998, recall = 0.009195561087811537.\n",
      "Training on epoch 45 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08404255319148934, recall = 0.007669308230383894.\n",
      "Training on epoch 45 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08105263157894733, recall = 0.006474921700514897.\n",
      "Training on epoch 45 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.10459770114942524, recall = 0.007924078253889843.\n",
      "\n",
      "Training on 45 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 46 epoch\n",
      "Training on epoch 46 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0789473684210526, recall = 0.006498879137784441.\n",
      "Training on epoch 46 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09784946236559133, recall = 0.006591564866713938.\n",
      "Training on epoch 46 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09789473684210523, recall = 0.009936156187866413.\n",
      "Training on epoch 46 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10404040404040399, recall = 0.008964911126508022.\n",
      "Training on epoch 46 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09438202247191012, recall = 0.006850938385155506.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 46 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.09042553191489362, recall = 0.00705880677726066.\n",
      "Training on epoch 46 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.086734693877551, recall = 0.00799686482488464.\n",
      "Training on epoch 46 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09550561797752805, recall = 0.009659095351767255.\n",
      "\n",
      "Training on 46 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999998, recall = 0.007534500282814585.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 47 epoch\n",
      "Training on epoch 47 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0977272727272727, recall = 0.009098821067366756.\n",
      "Training on epoch 47 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.08478260869565217, recall = 0.006439759588107999.\n",
      "Training on epoch 47 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08863636363636361, recall = 0.008450223505402787.\n",
      "Training on epoch 47 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08411214953271022, recall = 0.006470994727255039.\n",
      "Training on epoch 47 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.06344086021505373, recall = 0.00720881398061683.\n",
      "Training on epoch 47 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.10326086956521734, recall = 0.008231415043844028.\n",
      "Training on epoch 47 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07999999999999996, recall = 0.007443529455149816.\n",
      "Training on epoch 47 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.10116279069767439, recall = 0.009160204583577214.\n",
      "\n",
      "Training on 47 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08599999999999994, recall = 0.0073456857765005525.\n",
      "\n",
      "Training on the 48 epoch\n",
      "Training on epoch 48 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08673469387755098, recall = 0.006846372873512647.\n",
      "Training on epoch 48 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09797979797979796, recall = 0.008456730070244842.\n",
      "Training on epoch 48 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08058252427184463, recall = 0.007749943165499181.\n",
      "Training on epoch 48 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09591836734693872, recall = 0.007141995881578041.\n",
      "Training on epoch 48 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08888888888888889, recall = 0.007517676331018504.\n",
      "Training on epoch 48 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08058252427184465, recall = 0.007412289408006209.\n",
      "Training on epoch 48 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07553191489361699, recall = 0.007612064242035425.\n",
      "Training on epoch 48 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09468085106382976, recall = 0.008714992631759982.\n",
      "\n",
      "Training on 48 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.00755877212747478.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 49 epoch\n",
      "Training on epoch 49 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09292929292929289, recall = 0.008460912546501356.\n",
      "Training on epoch 49 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09473684210526308, recall = 0.009162982493111564.\n",
      "Training on epoch 49 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0826086956521739, recall = 0.006521032769175994.\n",
      "Training on epoch 49 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08842105263157891, recall = 0.005182600231538933.\n",
      "Training on epoch 49 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09680851063829782, recall = 0.008066224557249492.\n",
      "Training on epoch 49 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08620689655172413, recall = 0.007561363044445562.\n",
      "Training on epoch 49 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09285714285714286, recall = 0.008580307331014269.\n",
      "Training on epoch 49 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09895833333333327, recall = 0.008493332937070509.\n",
      "\n",
      "Training on 49 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 50 epoch\n",
      "Training on epoch 50 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09081632653061222, recall = 0.007638069672194196.\n",
      "Training on epoch 50 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08817204301075267, recall = 0.00580806355895714.\n",
      "Training on epoch 50 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08260869565217391, recall = 0.007700315868997626.\n",
      "Training on epoch 50 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07173913043478257, recall = 0.0060111540713621535.\n",
      "Training on epoch 50 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08723404255319145, recall = 0.00940184185338767.\n",
      "Training on epoch 50 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10434782608695652, recall = 0.007009608380972652.\n",
      "Training on epoch 50 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08585858585858583, recall = 0.007569194702982727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 50 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07099999999999997, recall = 0.005660980684818188.\n",
      "\n",
      "Training on 50 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.00755877212747478.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 51 epoch\n",
      "Training on epoch 51 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09670329670329668, recall = 0.009114514403363028.\n",
      "Training on epoch 51 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0758241758241758, recall = 0.005707210451371663.\n",
      "Training on epoch 51 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.09204545454545454, recall = 0.007593019689916766.\n",
      "Training on epoch 51 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.00835027472357595.\n",
      "Training on epoch 51 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09354838709677414, recall = 0.007872079010015916.\n",
      "Training on epoch 51 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07684210526315786, recall = 0.006233766080552395.\n",
      "Training on epoch 51 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08749999999999998, recall = 0.007150423667286638.\n",
      "Training on epoch 51 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.10210526315789466, recall = 0.007523701281857669.\n",
      "\n",
      "Training on 51 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.007466363893954263.\n",
      "\n",
      "Training on the 52 epoch\n",
      "Training on epoch 52 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0989361702127659, recall = 0.009069577178405704.\n",
      "Training on epoch 52 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09791666666666665, recall = 0.009330561173824975.\n",
      "Training on epoch 52 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09662921348314604, recall = 0.006977345998730891.\n",
      "Training on epoch 52 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08421052631578944, recall = 0.008657053901997386.\n",
      "Training on epoch 52 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07934782608695651, recall = 0.007119808856229835.\n",
      "Training on epoch 52 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10416666666666663, recall = 0.008710857452243103.\n",
      "Training on epoch 52 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08526315789473683, recall = 0.0075326306656231965.\n",
      "Training on epoch 52 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08241758241758239, recall = 0.005856180040914816.\n",
      "\n",
      "Training on 52 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007545331267259722.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08599999999999997, recall = 0.0073385898138944115.\n",
      "\n",
      "Training on the 53 epoch\n",
      "Training on epoch 53 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09578947368421052, recall = 0.00841109140638521.\n",
      "Training on epoch 53 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10439560439560434, recall = 0.00932762711480598.\n",
      "Training on epoch 53 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07799999999999999, recall = 0.008813578610764278.\n",
      "Training on epoch 53 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.0811111111111111, recall = 0.00754820693519226.\n",
      "Training on epoch 53 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.10899999999999997, recall = 0.009072866341816565.\n",
      "Training on epoch 53 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09157894736842105, recall = 0.006005895813492317.\n",
      "Training on epoch 53 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08229166666666661, recall = 0.00859463636140112.\n",
      "Training on epoch 53 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0927083333333333, recall = 0.007775023018419514.\n",
      "\n",
      "Training on 53 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 54 epoch\n",
      "Training on epoch 54 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0917525773195876, recall = 0.007317610219740814.\n",
      "Training on epoch 54 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10515463917525766, recall = 0.00859336866980222.\n",
      "Training on epoch 54 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09239130434782607, recall = 0.0068882038560212355.\n",
      "Training on epoch 54 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08817204301075264, recall = 0.00789168325758721.\n",
      "Training on epoch 54 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08936170212765954, recall = 0.0077339298297454204.\n",
      "Training on epoch 54 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.10106382978723402, recall = 0.008716743251022924.\n",
      "Training on epoch 54 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07931034482758618, recall = 0.006612651329414893.\n",
      "Training on epoch 54 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09696969696969691, recall = 0.008250010098701343.\n",
      "\n",
      "Training on 54 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08799999999999997, recall = 0.0075343222497241645.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999995, recall = 0.007440503750836979.\n",
      "\n",
      "Training on the 55 epoch\n",
      "Training on epoch 55 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09999999999999999, recall = 0.008967880207884365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 55 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09775280898876401, recall = 0.007049134484586237.\n",
      "Training on epoch 55 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08494623655913977, recall = 0.006789170760486529.\n",
      "Training on epoch 55 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08631578947368418, recall = 0.0060963807753334764.\n",
      "Training on epoch 55 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.10319148936170207, recall = 0.008299047991122542.\n",
      "Training on epoch 55 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0831578947368421, recall = 0.005682028359926614.\n",
      "Training on epoch 55 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08777777777777777, recall = 0.007822915533274613.\n",
      "Training on epoch 55 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07899999999999993, recall = 0.007248077028814852.\n",
      "\n",
      "Training on 55 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007778059513716059.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999995, recall = 0.007440503750836979.\n",
      "\n",
      "Training on the 56 epoch\n",
      "Training on epoch 56 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.00679594367196448.\n",
      "Training on epoch 56 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.0852631578947368, recall = 0.005745372197393118.\n",
      "Training on epoch 56 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10108695652173907, recall = 0.008612720590630675.\n",
      "Training on epoch 56 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.0900990099009901, recall = 0.00816268611259157.\n",
      "Training on epoch 56 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08617021276595745, recall = 0.007325023866774454.\n",
      "Training on epoch 56 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08947368421052627, recall = 0.008595805602376693.\n",
      "Training on epoch 56 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09479166666666665, recall = 0.006316448472512028.\n",
      "Training on epoch 56 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08936170212765956, recall = 0.0077161739524367855.\n",
      "\n",
      "Training on 56 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 57 epoch\n",
      "Training on epoch 57 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08762886597938141, recall = 0.008603548129638311.\n",
      "Training on epoch 57 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09247311827956987, recall = 0.006858488372336896.\n",
      "Training on epoch 57 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09484536082474221, recall = 0.006441759042967904.\n",
      "Training on epoch 57 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0835164835164835, recall = 0.007280755665733254.\n",
      "Training on epoch 57 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07199999999999998, recall = 0.006638093445036055.\n",
      "Training on epoch 57 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09569892473118279, recall = 0.007687873651771523.\n",
      "Training on epoch 57 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693181, and regularization loss is 3.4e-05.\n",
      " Top K precision = 0.09565217391304343, recall = 0.0075199749971693606.\n",
      "Training on epoch 57 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08666666666666661, recall = 0.00962596094647743.\n",
      "\n",
      "Training on 57 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999993, recall = 0.007492982653790566.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 58 epoch\n",
      "Training on epoch 58 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 7e-06.\n",
      " Top K precision = 0.08777777777777776, recall = 0.007907697559834812.\n",
      "Training on epoch 58 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0821052631578947, recall = 0.008783792049427133.\n",
      "Training on epoch 58 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.09895833333333331, recall = 0.007652828474213685.\n",
      "Training on epoch 58 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0858695652173913, recall = 0.005776074400637066.\n",
      "Training on epoch 58 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09999999999999995, recall = 0.008788467064289797.\n",
      "Training on epoch 58 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07916666666666666, recall = 0.00814347237138789.\n",
      "Training on epoch 58 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09494949494949492, recall = 0.008801170126447964.\n",
      "Training on epoch 58 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08876404494382018, recall = 0.008717768096645838.\n",
      "\n",
      "Training on 58 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08850000000000001, recall = 0.007497043732413048.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 59 epoch\n",
      "Training on epoch 59 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07010309278350511, recall = 0.007499288756379596.\n",
      "Training on epoch 59 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08478260869565216, recall = 0.006487907187392306.\n",
      "Training on epoch 59 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0717171717171717, recall = 0.005904487417274536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 59 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08085106382978721, recall = 0.007511655021364743.\n",
      "Training on epoch 59 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08526315789473682, recall = 0.008697523850264724.\n",
      "Training on epoch 59 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08888888888888886, recall = 0.008215216110693523.\n",
      "Training on epoch 59 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09032258064516127, recall = 0.009859247102465538.\n",
      "Training on epoch 59 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08350515463917524, recall = 0.00682858766234664.\n",
      "\n",
      "Training on 59 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 60 epoch\n",
      "Training on epoch 60 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08620689655172412, recall = 0.0072749124894368284.\n",
      "Training on epoch 60 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09021739130434779, recall = 0.007221745590727037.\n",
      "Training on epoch 60 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10210526315789467, recall = 0.010221236140010128.\n",
      "Training on epoch 60 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09690721649484532, recall = 0.0071860501958491375.\n",
      "Training on epoch 60 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08041237113402061, recall = 0.006866322768641692.\n",
      "Training on epoch 60 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09148936170212764, recall = 0.006982830345494733.\n",
      "Training on epoch 60 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0873563218390804, recall = 0.007973391232177423.\n",
      "Training on epoch 60 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09405940594059406, recall = 0.00811517853186093.\n",
      "\n",
      "Training on 60 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 61 epoch\n",
      "Training on epoch 61 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09263157894736836, recall = 0.008174051474957408.\n",
      "Training on epoch 61 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08191489361702127, recall = 0.006423804157860988.\n",
      "Training on epoch 61 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09148936170212764, recall = 0.008123089235912652.\n",
      "Training on epoch 61 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09583333333333328, recall = 0.00847330031191984.\n",
      "Training on epoch 61 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08865979381443297, recall = 0.007097167095820824.\n",
      "Training on epoch 61 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08958333333333335, recall = 0.007549369958249115.\n",
      "Training on epoch 61 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08421052631578943, recall = 0.007679092789288541.\n",
      "Training on epoch 61 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09354838709677414, recall = 0.006938260130421429.\n",
      "\n",
      "Training on 61 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 62 epoch\n",
      "Training on epoch 62 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.087, recall = 0.006601404391568982.\n",
      "Training on epoch 62 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0897959183673469, recall = 0.006650742537345182.\n",
      "Training on epoch 62 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.08999999999999994, recall = 0.00788121984727548.\n",
      "Training on epoch 62 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09479166666666662, recall = 0.007558955489555409.\n",
      "Training on epoch 62 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08913043478260867, recall = 0.007630277621248784.\n",
      "Training on epoch 62 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09999999999999999, recall = 0.008574616052330161.\n",
      "Training on epoch 62 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08645833333333329, recall = 0.007805471181651022.\n",
      "Training on epoch 62 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09892473118279563, recall = 0.008487024882048173.\n",
      "\n",
      "Training on 62 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999994, recall = 0.007469486413189065.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 63 epoch\n",
      "Training on epoch 63 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08571428571428569, recall = 0.00666918913552514.\n",
      "Training on epoch 63 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0929292929292929, recall = 0.006877036875221001.\n",
      "Training on epoch 63 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07111111111111111, recall = 0.006920677047261511.\n",
      "Training on epoch 63 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08777777777777775, recall = 0.00833674902510189.\n",
      "Training on epoch 63 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.0947916666666666, recall = 0.007979412084914008.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 63 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09587628865979375, recall = 0.008424269441450468.\n",
      "Training on epoch 63 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08556701030927832, recall = 0.0072745790067943765.\n",
      "Training on epoch 63 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09032258064516126, recall = 0.006985230323657441.\n",
      "\n",
      "Training on 63 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 64 epoch\n",
      "Training on epoch 64 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08265306122448976, recall = 0.008689519964827166.\n",
      "Training on epoch 64 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09799999999999993, recall = 0.008141604109679193.\n",
      "Training on epoch 64 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10485436893203876, recall = 0.008369428984401227.\n",
      "Training on epoch 64 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07608695652173911, recall = 0.007252317458079159.\n",
      "Training on epoch 64 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.09450549450549449, recall = 0.007225266683291148.\n",
      "Training on epoch 64 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08163265306122444, recall = 0.008210268968769235.\n",
      "Training on epoch 64 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.07446808510638295, recall = 0.007677520960879125.\n",
      "Training on epoch 64 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08863636363636361, recall = 0.008821114825228675.\n",
      "\n",
      "Training on 64 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999993, recall = 0.007648057841760492.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 65 epoch\n",
      "Training on epoch 65 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08791208791208789, recall = 0.00719410939088259.\n",
      "Training on epoch 65 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693181, and regularization loss is 3.4e-05.\n",
      " Top K precision = 0.10312499999999995, recall = 0.009546997983020323.\n",
      "Training on epoch 65 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08854166666666663, recall = 0.008000771961064456.\n",
      "Training on epoch 65 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.09191919191919186, recall = 0.007402799867316006.\n",
      "Training on epoch 65 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08383838383838382, recall = 0.006929038157715698.\n",
      "Training on epoch 65 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08924731182795696, recall = 0.00629558179771517.\n",
      "Training on epoch 65 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09052631578947365, recall = 0.0075207174619938985.\n",
      "Training on epoch 65 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08399999999999995, recall = 0.007692652074682084.\n",
      "\n",
      "Training on 65 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474772.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 66 epoch\n",
      "Training on epoch 66 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07653061224489795, recall = 0.006901867120212062.\n",
      "Training on epoch 66 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08602150537634405, recall = 0.007974743732356966.\n",
      "Training on epoch 66 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08865979381443295, recall = 0.008838557731994372.\n",
      "Training on epoch 66 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09468085106382973, recall = 0.00605174738243635.\n",
      "Training on epoch 66 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08229166666666667, recall = 0.008984277168050987.\n",
      "Training on epoch 66 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10106382978723402, recall = 0.008375427151508128.\n",
      "Training on epoch 66 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08437499999999999, recall = 0.006403042982282797.\n",
      "Training on epoch 66 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10816326530612239, recall = 0.008445299761034603.\n",
      "\n",
      "Training on 66 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999998, recall = 0.00752828432259673.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 67 epoch\n",
      "Training on epoch 67 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0851063829787234, recall = 0.007255454899175927.\n",
      "Training on epoch 67 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08888888888888888, recall = 0.008305310394012408.\n",
      "Training on epoch 67 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09670329670329669, recall = 0.008374407162822532.\n",
      "Training on epoch 67 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09795918367346937, recall = 0.008321567916981933.\n",
      "Training on epoch 67 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10549450549450544, recall = 0.007584900094864758.\n",
      "Training on epoch 67 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09784946236559137, recall = 0.007845282518150667.\n",
      "Training on epoch 67 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0741935483870968, recall = 0.006204294194211544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 67 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08899999999999997, recall = 0.008378940297175138.\n",
      "\n",
      "Training on 67 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 68 epoch\n",
      "Training on epoch 68 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08979591836734693, recall = 0.007542240183862117.\n",
      "Training on epoch 68 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08437499999999999, recall = 0.008521667765364201.\n",
      "Training on epoch 68 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09479166666666662, recall = 0.00795979820883355.\n",
      "Training on epoch 68 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.06907216494845358, recall = 0.006183492351514608.\n",
      "Training on epoch 68 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0989583333333333, recall = 0.008499841376809958.\n",
      "Training on epoch 68 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08478260869565216, recall = 0.008035416536852231.\n",
      "Training on epoch 68 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.083695652173913, recall = 0.007953889491634033.\n",
      "Training on epoch 68 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.06559139784946237, recall = 0.0052988094455414785.\n",
      "\n",
      "Training on 68 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08999999999999997, recall = 0.007588520745876587.\n",
      "\n",
      "Training on the 69 epoch\n",
      "Training on epoch 69 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08602150537634405, recall = 0.007854506478040278.\n",
      "Training on epoch 69 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08494623655913976, recall = 0.0057438730343712975.\n",
      "Training on epoch 69 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09354838709677417, recall = 0.007236991184987043.\n",
      "Training on epoch 69 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08421052631578943, recall = 0.0073797278013454405.\n",
      "Training on epoch 69 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09574468085106377, recall = 0.007985079948272435.\n",
      "Training on epoch 69 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08235294117647057, recall = 0.00660666259313697.\n",
      "Training on epoch 69 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09456521739130432, recall = 0.009237260969463009.\n",
      "Training on epoch 69 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09199999999999997, recall = 0.008014996420323668.\n",
      "\n",
      "Training on 69 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 70 epoch\n",
      "Training on epoch 70 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.090625, recall = 0.007899271496488494.\n",
      "Training on epoch 70 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09578947368421048, recall = 0.008330251336668523.\n",
      "Training on epoch 70 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10103092783505149, recall = 0.007971682010269331.\n",
      "Training on epoch 70 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07311827956989246, recall = 0.006364365373938919.\n",
      "Training on epoch 70 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08068181818181816, recall = 0.0071106051311259355.\n",
      "Training on epoch 70 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.0858695652173913, recall = 0.0069051366672478005.\n",
      "Training on epoch 70 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09587628865979375, recall = 0.00867253568655473.\n",
      "Training on epoch 70 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09789473684210521, recall = 0.007478866113930554.\n",
      "\n",
      "Training on 70 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.0889999999999999, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 71 epoch\n",
      "Training on epoch 71 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.0737373737373737, recall = 0.00699673384865222.\n",
      "Training on epoch 71 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09042553191489362, recall = 0.007210160748382354.\n",
      "Training on epoch 71 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09999999999999998, recall = 0.007474959246197446.\n",
      "Training on epoch 71 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09560439560439556, recall = 0.007880517706250775.\n",
      "Training on epoch 71 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08799999999999997, recall = 0.007968735493896739.\n",
      "Training on epoch 71 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09578947368421047, recall = 0.008252890817960618.\n",
      "Training on epoch 71 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0702127659574468, recall = 0.006111015019539803.\n",
      "Training on epoch 71 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09090909090909087, recall = 0.00779717973181672.\n",
      "\n",
      "Training on 71 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 72 epoch\n",
      "Training on epoch 72 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08977272727272724, recall = 0.007518882895995654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 72 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07899999999999997, recall = 0.005814679994600506.\n",
      "Training on epoch 72 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.10777777777777775, recall = 0.007544491226041996.\n",
      "Training on epoch 72 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.098, recall = 0.008073810640573269.\n",
      "Training on epoch 72 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08762886597938141, recall = 0.008489158244715564.\n",
      "Training on epoch 72 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09347826086956518, recall = 0.006157584569866209.\n",
      "Training on epoch 72 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09797979797979792, recall = 0.009294832761746136.\n",
      "Training on epoch 72 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.09347826086956518, recall = 0.008342565140166326.\n",
      "\n",
      "Training on 72 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 73 epoch\n",
      "Training on epoch 73 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.10199999999999994, recall = 0.008541581208427528.\n",
      "Training on epoch 73 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09247311827956983, recall = 0.0070976849048673095.\n",
      "Training on epoch 73 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.0989690721649484, recall = 0.008485217522500206.\n",
      "Training on epoch 73 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07999999999999997, recall = 0.0063556881085988235.\n",
      "Training on epoch 73 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09999999999999995, recall = 0.00614694054453878.\n",
      "Training on epoch 73 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09787234042553188, recall = 0.007868959938896521.\n",
      "Training on epoch 73 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08775510204081631, recall = 0.008381075387645452.\n",
      "Training on epoch 73 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09578947368421048, recall = 0.007638571364480058.\n",
      "\n",
      "Training on 73 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999995, recall = 0.007440503750836979.\n",
      "\n",
      "Training on the 74 epoch\n",
      "Training on epoch 74 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09479166666666665, recall = 0.00736879856105621.\n",
      "Training on epoch 74 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0978260869565217, recall = 0.008313594596989026.\n",
      "Training on epoch 74 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08404255319148936, recall = 0.006899665276468955.\n",
      "Training on epoch 74 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08749999999999998, recall = 0.008962151122758227.\n",
      "Training on epoch 74 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09325842696629212, recall = 0.009294718549270468.\n",
      "Training on epoch 74 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09139784946236557, recall = 0.00829722516189073.\n",
      "Training on epoch 74 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.1083333333333333, recall = 0.009014976810143112.\n",
      "Training on epoch 74 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09999999999999998, recall = 0.007686195733896957.\n",
      "\n",
      "Training on 74 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 75 epoch\n",
      "Training on epoch 75 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09042553191489358, recall = 0.007946809925588728.\n",
      "Training on epoch 75 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09479166666666661, recall = 0.009111038308093346.\n",
      "Training on epoch 75 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693153, and regularization loss is 6e-06.\n",
      " Top K precision = 0.09560439560439554, recall = 0.008732044867794197.\n",
      "Training on epoch 75 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.1042553191489361, recall = 0.00807173771255329.\n",
      "Training on epoch 75 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08247422680412364, recall = 0.00722169659367186.\n",
      "Training on epoch 75 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0908045977011494, recall = 0.0063230885431486425.\n",
      "Training on epoch 75 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.08723404255319148, recall = 0.008397129402507916.\n",
      "Training on epoch 75 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09499999999999999, recall = 0.0074539430855336646.\n",
      "\n",
      "Training on 75 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 76 epoch\n",
      "Training on epoch 76 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07204301075268815, recall = 0.006570422776016103.\n",
      "Training on epoch 76 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0947368421052631, recall = 0.007534957758141781.\n",
      "Training on epoch 76 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09387755102040812, recall = 0.009408072424876467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 76 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08787878787878783, recall = 0.008128322360440757.\n",
      "Training on epoch 76 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10099009900990097, recall = 0.007654823019769079.\n",
      "Training on epoch 76 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07916666666666665, recall = 0.006543244937677157.\n",
      "Training on epoch 76 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09799999999999995, recall = 0.008515491221905118.\n",
      "Training on epoch 76 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09583333333333327, recall = 0.0070183654698258114.\n",
      "\n",
      "Training on 76 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 77 epoch\n",
      "Training on epoch 77 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08539325842696627, recall = 0.007921832426156837.\n",
      "Training on epoch 77 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09101123595505616, recall = 0.009274064214802459.\n",
      "Training on epoch 77 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08152173913043477, recall = 0.0069100272247057766.\n",
      "Training on epoch 77 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09270833333333328, recall = 0.007486997071209224.\n",
      "Training on epoch 77 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09795918367346933, recall = 0.009253846591373084.\n",
      "Training on epoch 77 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09042553191489357, recall = 0.008702977246900454.\n",
      "Training on epoch 77 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09368421052631576, recall = 0.008192368142480973.\n",
      "Training on epoch 77 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08749999999999998, recall = 0.007369297819002147.\n",
      "\n",
      "Training on 77 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999995, recall = 0.007629194662686044.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 78 epoch\n",
      "Training on epoch 78 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09468085106382976, recall = 0.007449414638740756.\n",
      "Training on epoch 78 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09999999999999994, recall = 0.007442404557160237.\n",
      "Training on epoch 78 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07634408602150537, recall = 0.006141054673453684.\n",
      "Training on epoch 78 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09021739130434782, recall = 0.00794435553496796.\n",
      "Training on epoch 78 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07849462365591396, recall = 0.009115586952532576.\n",
      "Training on epoch 78 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09126213592233007, recall = 0.007718818850929096.\n",
      "Training on epoch 78 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07840909090909086, recall = 0.008056186823918888.\n",
      "Training on epoch 78 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0917525773195876, recall = 0.0074018558586095235.\n",
      "\n",
      "Training on 78 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999995, recall = 0.0075725083912110405.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 79 epoch\n",
      "Training on epoch 79 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08775510204081631, recall = 0.006790268547982126.\n",
      "Training on epoch 79 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08023255813953488, recall = 0.005269564317441007.\n",
      "Training on epoch 79 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0813186813186813, recall = 0.0081080382896475.\n",
      "Training on epoch 79 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10303030303030297, recall = 0.008132406431057938.\n",
      "Training on epoch 79 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07346938775510203, recall = 0.006164033937776022.\n",
      "Training on epoch 79 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09183673469387751, recall = 0.008911821729373284.\n",
      "Training on epoch 79 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09456521739130432, recall = 0.007671894973074722.\n",
      "Training on epoch 79 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.11263157894736836, recall = 0.00820175328828731.\n",
      "\n",
      "Training on 79 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 80 epoch\n",
      "Training on epoch 80 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08723404255319145, recall = 0.0066938736810245964.\n",
      "Training on epoch 80 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08585858585858579, recall = 0.008565166771216753.\n",
      "Training on epoch 80 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10638297872340417, recall = 0.009262266071180183.\n",
      "Training on epoch 80 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10288461538461532, recall = 0.008900118642529063.\n",
      "Training on epoch 80 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09891304347826083, recall = 0.008591411164077647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 80 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0869565217391304, recall = 0.006172095507435575.\n",
      "Training on epoch 80 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09569892473118274, recall = 0.006815702718360574.\n",
      "Training on epoch 80 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09021739130434778, recall = 0.007220447576985366.\n",
      "\n",
      "Training on 80 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 81 epoch\n",
      "Training on epoch 81 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.1053191489361702, recall = 0.009093177920295804.\n",
      "Training on epoch 81 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08387096774193546, recall = 0.008182140255536688.\n",
      "Training on epoch 81 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.0909090909090909, recall = 0.00611663580637142.\n",
      "Training on epoch 81 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0956043956043956, recall = 0.006613723036898685.\n",
      "Training on epoch 81 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07789473684210522, recall = 0.007044822551425987.\n",
      "Training on epoch 81 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08041237113402061, recall = 0.007578428637417055.\n",
      "Training on epoch 81 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0858695652173913, recall = 0.006742683418268904.\n",
      "Training on epoch 81 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08510638297872336, recall = 0.006860563727918276.\n",
      "\n",
      "Training on 81 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.00755877212747478.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075790150424545335.\n",
      "\n",
      "Training on the 82 epoch\n",
      "Training on epoch 82 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08725490196078428, recall = 0.007177484323202868.\n",
      "Training on epoch 82 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693181, and regularization loss is 3.4e-05.\n",
      " Top K precision = 0.10109890109890107, recall = 0.009265731452822439.\n",
      "Training on epoch 82 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09157894736842102, recall = 0.008148983441045884.\n",
      "Training on epoch 82 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09489795918367339, recall = 0.007784099015936671.\n",
      "Training on epoch 82 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.10631578947368417, recall = 0.008226039942741554.\n",
      "Training on epoch 82 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0726315789473684, recall = 0.006658094330202704.\n",
      "Training on epoch 82 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.08631578947368418, recall = 0.008222045188609885.\n",
      "Training on epoch 82 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07999999999999997, recall = 0.007156139493321615.\n",
      "\n",
      "Training on 82 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999993, recall = 0.007469486413189061.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 83 epoch\n",
      "Training on epoch 83 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08888888888888884, recall = 0.007193551630267408.\n",
      "Training on epoch 83 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08725490196078428, recall = 0.007764872151500978.\n",
      "Training on epoch 83 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07717391304347826, recall = 0.006203031578210133.\n",
      "Training on epoch 83 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09191919191919186, recall = 0.00823167977084082.\n",
      "Training on epoch 83 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09684210526315787, recall = 0.007641608432980896.\n",
      "Training on epoch 83 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.08484848484848485, recall = 0.007773330631667679.\n",
      "Training on epoch 83 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08043478260869565, recall = 0.007723800172583774.\n",
      "Training on epoch 83 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08750000000000001, recall = 0.007488323987180496.\n",
      "\n",
      "Training on 83 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007549447986425953.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 84 epoch\n",
      "Training on epoch 84 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08999999999999994, recall = 0.006203571320492485.\n",
      "Training on epoch 84 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08404255319148933, recall = 0.007691469918796434.\n",
      "Training on epoch 84 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08350515463917525, recall = 0.007797345094049508.\n",
      "Training on epoch 84 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0793478260869565, recall = 0.008212404733843258.\n",
      "Training on epoch 84 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693178, and regularization loss is 3.1e-05.\n",
      " Top K precision = 0.08421052631578943, recall = 0.007922268986518462.\n",
      "Training on epoch 84 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08510638297872336, recall = 0.006637962870394737.\n",
      "Training on epoch 84 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07252747252747252, recall = 0.00589634282366947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 84 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.07311827956989247, recall = 0.006141790371155314.\n",
      "\n",
      "Training on 84 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 85 epoch\n",
      "Training on epoch 85 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0855670103092783, recall = 0.008340178427594455.\n",
      "Training on epoch 85 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08686868686868682, recall = 0.00897279572396515.\n",
      "Training on epoch 85 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08709677419354836, recall = 0.007671379848509779.\n",
      "Training on epoch 85 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09320388349514558, recall = 0.007875773448391646.\n",
      "Training on epoch 85 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0934065934065934, recall = 0.006305179943375466.\n",
      "Training on epoch 85 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08437499999999999, recall = 0.00830496984395829.\n",
      "Training on epoch 85 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08404255319148934, recall = 0.008068133488879433.\n",
      "Training on epoch 85 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08043478260869562, recall = 0.008984721149975509.\n",
      "\n",
      "Training on 85 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999994, recall = 0.007445135763838413.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 86 epoch\n",
      "Training on epoch 86 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08762886597938142, recall = 0.008428428616646713.\n",
      "Training on epoch 86 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09032258064516122, recall = 0.008444229403940254.\n",
      "Training on epoch 86 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08229166666666662, recall = 0.0068956151671757905.\n",
      "Training on epoch 86 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07741935483870967, recall = 0.006022302264227049.\n",
      "Training on epoch 86 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08124999999999999, recall = 0.007330107159735447.\n",
      "Training on epoch 86 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08494623655913976, recall = 0.006226218544023382.\n",
      "Training on epoch 86 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.08494623655913978, recall = 0.008055300285249749.\n",
      "Training on epoch 86 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09793814432989686, recall = 0.00922749596090981.\n",
      "\n",
      "Training on 86 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08649999999999997, recall = 0.007381209894255463.\n",
      "\n",
      "Training on the 87 epoch\n",
      "Training on epoch 87 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10103092783505152, recall = 0.0085819989580864.\n",
      "Training on epoch 87 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08723404255319145, recall = 0.008194453107863217.\n",
      "Training on epoch 87 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09191919191919186, recall = 0.007935552357265176.\n",
      "Training on epoch 87 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09247311827956987, recall = 0.008262357599079912.\n",
      "Training on epoch 87 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.07916666666666668, recall = 0.0074584268922430015.\n",
      "Training on epoch 87 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0787234042553191, recall = 0.007498195640323932.\n",
      "Training on epoch 87 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10208333333333326, recall = 0.009149511190907417.\n",
      "Training on epoch 87 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09029126213592228, recall = 0.008968748191297024.\n",
      "\n",
      "Training on 87 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999995, recall = 0.007581093556046204.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075790150424545335.\n",
      "\n",
      "Training on the 88 epoch\n",
      "Training on epoch 88 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09042553191489358, recall = 0.0060395770292479.\n",
      "Training on epoch 88 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09795918367346934, recall = 0.007143903355589928.\n",
      "Training on epoch 88 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0835164835164835, recall = 0.007148047211235222.\n",
      "Training on epoch 88 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.10212765957446802, recall = 0.008913914094383187.\n",
      "Training on epoch 88 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09139784946236557, recall = 0.006877562788933776.\n",
      "Training on epoch 88 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.108695652173913, recall = 0.007936578786762268.\n",
      "Training on epoch 88 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08105263157894735, recall = 0.006806220008116078.\n",
      "Training on epoch 88 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08484848484848481, recall = 0.008525669928392605.\n",
      "\n",
      "Training on 88 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08999999999999997, recall = 0.007588520745876587.\n",
      "\n",
      "Training on the 89 epoch\n",
      "Training on epoch 89 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08599999999999998, recall = 0.00800196738575429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 89 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08775510204081625, recall = 0.006786354471672592.\n",
      "Training on epoch 89 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08085106382978721, recall = 0.007978324991423818.\n",
      "Training on epoch 89 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07234042553191489, recall = 0.0045883187638133755.\n",
      "Training on epoch 89 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0896907216494845, recall = 0.007754905705733345.\n",
      "Training on epoch 89 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10199999999999995, recall = 0.00786546902150133.\n",
      "Training on epoch 89 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09489795918367344, recall = 0.007930210624557107.\n",
      "Training on epoch 89 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09255319148936171, recall = 0.008936744191986628.\n",
      "\n",
      "Training on 89 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 90 epoch\n",
      "Training on epoch 90 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0842696629213483, recall = 0.007741600366494062.\n",
      "Training on epoch 90 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07526881720430106, recall = 0.006873713038045188.\n",
      "Training on epoch 90 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09072164948453604, recall = 0.007621850178095068.\n",
      "Training on epoch 90 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08829787234042553, recall = 0.008150186601835311.\n",
      "Training on epoch 90 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09795918367346931, recall = 0.007769174403039828.\n",
      "Training on epoch 90 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.10117647058823527, recall = 0.007532029983479361.\n",
      "Training on epoch 90 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08817204301075267, recall = 0.007640224588883424.\n",
      "Training on epoch 90 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09473684210526312, recall = 0.009183974978209579.\n",
      "\n",
      "Training on 90 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007492982653790569.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 91 epoch\n",
      "Training on epoch 91 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09450549450549445, recall = 0.010188055463336822.\n",
      "Training on epoch 91 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0683673469387755, recall = 0.006733278064182769.\n",
      "Training on epoch 91 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07849462365591395, recall = 0.007413934047843124.\n",
      "Training on epoch 91 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09569892473118281, recall = 0.0069932265612586975.\n",
      "Training on epoch 91 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09375000000000001, recall = 0.00735030858707345.\n",
      "Training on epoch 91 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09062499999999997, recall = 0.007613216210913851.\n",
      "Training on epoch 91 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.0689655172413793, recall = 0.007820232073248468.\n",
      "Training on epoch 91 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.10227272727272724, recall = 0.00842651270359824.\n",
      "\n",
      "Training on 91 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.007488775691019712.\n",
      "\n",
      "Training on the 92 epoch\n",
      "Training on epoch 92 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.0835164835164835, recall = 0.006291084881076352.\n",
      "Training on epoch 92 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08478260869565214, recall = 0.0061819587898856295.\n",
      "Training on epoch 92 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09468085106382973, recall = 0.008076726583127622.\n",
      "Training on epoch 92 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09999999999999998, recall = 0.005525335083407437.\n",
      "Training on epoch 92 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09677419354838708, recall = 0.008656769055301092.\n",
      "Training on epoch 92 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08350515463917525, recall = 0.007688461859875638.\n",
      "Training on epoch 92 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08229166666666664, recall = 0.007649652900190121.\n",
      "Training on epoch 92 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07549019607843135, recall = 0.007134219062483144.\n",
      "\n",
      "Training on 92 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 93 epoch\n",
      "Training on epoch 93 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08526315789473683, recall = 0.007350695334588215.\n",
      "Training on epoch 93 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08602150537634409, recall = 0.006718531052645375.\n",
      "Training on epoch 93 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08979591836734689, recall = 0.008327032564745079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 93 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0857142857142857, recall = 0.007372522053202887.\n",
      "Training on epoch 93 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.2e-05.\n",
      " Top K precision = 0.07857142857142854, recall = 0.0065046340077849225.\n",
      "Training on epoch 93 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09239130434782608, recall = 0.007660686623973262.\n",
      "Training on epoch 93 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07471264367816091, recall = 0.007610751808285112.\n",
      "Training on epoch 93 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08947368421052632, recall = 0.008308070377201585.\n",
      "\n",
      "Training on 93 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 94 epoch\n",
      "Training on epoch 94 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09381443298969068, recall = 0.007914363520698783.\n",
      "Training on epoch 94 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09239130434782608, recall = 0.006378557674517612.\n",
      "Training on epoch 94 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07368421052631578, recall = 0.006784651554128285.\n",
      "Training on epoch 94 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08383838383838381, recall = 0.007171837816600848.\n",
      "Training on epoch 94 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07551020408163263, recall = 0.00757440527311318.\n",
      "Training on epoch 94 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0897959183673469, recall = 0.006268676014750344.\n",
      "Training on epoch 94 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09499999999999995, recall = 0.007037488747816729.\n",
      "Training on epoch 94 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0851063829787234, recall = 0.0059731149230289856.\n",
      "\n",
      "Training on 94 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 95 epoch\n",
      "Training on epoch 95 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08969072164948451, recall = 0.006566435434638089.\n",
      "Training on epoch 95 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08695652173913042, recall = 0.007328829429133617.\n",
      "Training on epoch 95 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07816091954022986, recall = 0.007445024469686036.\n",
      "Training on epoch 95 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.006890937219779546.\n",
      "Training on epoch 95 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09560439560439558, recall = 0.009212680803368555.\n",
      "Training on epoch 95 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09294117647058828, recall = 0.007285441202355709.\n",
      "Training on epoch 95 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0938144329896907, recall = 0.00813922433043646.\n",
      "Training on epoch 95 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08446601941747568, recall = 0.008127180368275502.\n",
      "\n",
      "Training on 95 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08900000000000001, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 96 epoch\n",
      "Training on epoch 96 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.11075268817204297, recall = 0.007988168616065805.\n",
      "Training on epoch 96 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09368421052631576, recall = 0.008283568778924822.\n",
      "Training on epoch 96 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07912087912087909, recall = 0.007175487384378826.\n",
      "Training on epoch 96 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10599999999999993, recall = 0.008432506800580957.\n",
      "Training on epoch 96 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07415730337078649, recall = 0.00537444382922592.\n",
      "Training on epoch 96 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08762886597938141, recall = 0.007831155562216046.\n",
      "Training on epoch 96 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08265306122448979, recall = 0.00708132981488087.\n",
      "Training on epoch 96 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07608695652173911, recall = 0.00815898819996257.\n",
      "\n",
      "Training on 96 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 97 epoch\n",
      "Training on epoch 97 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08735632183908047, recall = 0.008036372803265596.\n",
      "Training on epoch 97 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08181818181818179, recall = 0.007109821258928679.\n",
      "Training on epoch 97 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07777777777777778, recall = 0.005548324778086718.\n",
      "Training on epoch 97 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.10421052631578938, recall = 0.010188509437007557.\n",
      "Training on epoch 97 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08709677419354836, recall = 0.007580689975641596.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 97 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07708333333333331, recall = 0.00620068322462771.\n",
      "Training on epoch 97 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.07411764705882351, recall = 0.007419053707606203.\n",
      "Training on epoch 97 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09565217391304345, recall = 0.008997160007316748.\n",
      "\n",
      "Training on 97 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 98 epoch\n",
      "Training on epoch 98 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0872549019607843, recall = 0.006088515042341306.\n",
      "Training on epoch 98 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09583333333333327, recall = 0.00873291802185352.\n",
      "Training on epoch 98 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08282828282828278, recall = 0.007895849331613596.\n",
      "Training on epoch 98 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09374999999999996, recall = 0.008218736473802302.\n",
      "Training on epoch 98 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0858585858585858, recall = 0.007215494974574502.\n",
      "Training on epoch 98 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09892473118279566, recall = 0.007869037975936816.\n",
      "Training on epoch 98 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08241758241758243, recall = 0.006424880319547855.\n",
      "Training on epoch 98 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08421052631578944, recall = 0.007684174904382921.\n",
      "\n",
      "Training on 98 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.00755877212747478.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 99 epoch\n",
      "Training on epoch 99 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0927083333333333, recall = 0.00872445344705919.\n",
      "Training on epoch 99 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08681318681318682, recall = 0.007282495233365754.\n",
      "Training on epoch 99 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08750000000000001, recall = 0.007999433583047161.\n",
      "Training on epoch 99 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08787878787878783, recall = 0.00830568008125781.\n",
      "Training on epoch 99 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09120879120879118, recall = 0.007191873724803895.\n",
      "Training on epoch 99 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08163265306122444, recall = 0.007382895402370379.\n",
      "Training on epoch 99 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0783505154639175, recall = 0.006935136110520543.\n",
      "Training on epoch 99 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08901098901098899, recall = 0.007079514243769091.\n",
      "\n",
      "Training on 99 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 100 epoch\n",
      "Training on epoch 100 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0857142857142857, recall = 0.007198753634952855.\n",
      "Training on epoch 100 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09468085106382973, recall = 0.008681729366563012.\n",
      "Training on epoch 100 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09361702127659571, recall = 0.008404927454243611.\n",
      "Training on epoch 100 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08299999999999995, recall = 0.007358118889219556.\n",
      "Training on epoch 100 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.06451612903225805, recall = 0.006322275429698172.\n",
      "Training on epoch 100 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.0938775510204081, recall = 0.009484402993719472.\n",
      "Training on epoch 100 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08969072164948452, recall = 0.008008100079497918.\n",
      "Training on epoch 100 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09780219780219775, recall = 0.008363334631242102.\n",
      "\n",
      "Training on 100 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 101 epoch\n",
      "Training on epoch 101 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.10329670329670325, recall = 0.008108039969153952.\n",
      "Training on epoch 101 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07878787878787875, recall = 0.0047192840998342535.\n",
      "Training on epoch 101 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07840909090909089, recall = 0.007499892740050918.\n",
      "Training on epoch 101 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08409090909090905, recall = 0.006841138522784035.\n",
      "Training on epoch 101 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.006913100282721891.\n",
      "Training on epoch 101 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.07979797979797976, recall = 0.006756783968487587.\n",
      "Training on epoch 101 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08913043478260867, recall = 0.009238643807628856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 101 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.09583333333333331, recall = 0.00772018709991461.\n",
      "\n",
      "Training on 101 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08799999999999997, recall = 0.0075343222497241645.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 102 epoch\n",
      "Training on epoch 102 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08602150537634405, recall = 0.006350175595683858.\n",
      "Training on epoch 102 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07899999999999997, recall = 0.007410691224752983.\n",
      "Training on epoch 102 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09787234042553189, recall = 0.007741015161109774.\n",
      "Training on epoch 102 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07802197802197802, recall = 0.008225324848673662.\n",
      "Training on epoch 102 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0891304347826087, recall = 0.008947145585712822.\n",
      "Training on epoch 102 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09347826086956522, recall = 0.00868134784156031.\n",
      "Training on epoch 102 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0818181818181818, recall = 0.006688947015435157.\n",
      "Training on epoch 102 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07319587628865974, recall = 0.006950661148998497.\n",
      "\n",
      "Training on 102 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 103 epoch\n",
      "Training on epoch 103 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.2e-05.\n",
      " Top K precision = 0.10430107526881714, recall = 0.009322960182669223.\n",
      "Training on epoch 103 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07525773195876287, recall = 0.007820711385610782.\n",
      "Training on epoch 103 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07699999999999997, recall = 0.007231538372537687.\n",
      "Training on epoch 103 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07399999999999995, recall = 0.007452986235582144.\n",
      "Training on epoch 103 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09888888888888886, recall = 0.00820999960972436.\n",
      "Training on epoch 103 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08383838383838381, recall = 0.00926757863485016.\n",
      "Training on epoch 103 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09399999999999997, recall = 0.00866785212125092.\n",
      "Training on epoch 103 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09550561797752805, recall = 0.007122054025852403.\n",
      "\n",
      "Training on 103 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08799999999999995, recall = 0.007534322249724164.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 104 epoch\n",
      "Training on epoch 104 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09263157894736841, recall = 0.008915145872020865.\n",
      "Training on epoch 104 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09347826086956518, recall = 0.007865842866869888.\n",
      "Training on epoch 104 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09662921348314604, recall = 0.007691580255957252.\n",
      "Training on epoch 104 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.08043478260869565, recall = 0.007590387108428493.\n",
      "Training on epoch 104 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07319587628865978, recall = 0.0072380854572120824.\n",
      "Training on epoch 104 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09021739130434782, recall = 0.008581308198926638.\n",
      "Training on epoch 104 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08631578947368418, recall = 0.008532838251360097.\n",
      "Training on epoch 104 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09687499999999999, recall = 0.00801627976231293.\n",
      "\n",
      "Training on 104 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.0889999999999999, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 105 epoch\n",
      "Training on epoch 105 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0826086956521739, recall = 0.006918446912855969.\n",
      "Training on epoch 105 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.10210526315789471, recall = 0.007436001036828536.\n",
      "Training on epoch 105 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09784946236559136, recall = 0.008804624659639918.\n",
      "Training on epoch 105 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07604166666666665, recall = 0.006618294976142999.\n",
      "Training on epoch 105 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09696969696969693, recall = 0.008721125971691031.\n",
      "Training on epoch 105 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09999999999999995, recall = 0.008626018377757625.\n",
      "Training on epoch 105 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09111111111111106, recall = 0.005999288326240731.\n",
      "Training on epoch 105 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09897959183673467, recall = 0.007236744503571611.\n",
      "\n",
      "Training on 105 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 106 epoch\n",
      "Training on epoch 106 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08526315789473682, recall = 0.007205180067401226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 106 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09599999999999995, recall = 0.007277284656055214.\n",
      "Training on epoch 106 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08817204301075264, recall = 0.006924584935551072.\n",
      "Training on epoch 106 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07173913043478264, recall = 0.007381658592038561.\n",
      "Training on epoch 106 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08673469387755098, recall = 0.0078638221855045.\n",
      "Training on epoch 106 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09784946236559139, recall = 0.007991072664806389.\n",
      "Training on epoch 106 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.0882978723404255, recall = 0.007551367413731795.\n",
      "Training on epoch 106 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09462365591397846, recall = 0.008268834181890145.\n",
      "\n",
      "Training on 106 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 107 epoch\n",
      "Training on epoch 107 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08421052631578946, recall = 0.007121879968602005.\n",
      "Training on epoch 107 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08777777777777777, recall = 0.0052599412992188534.\n",
      "Training on epoch 107 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08901098901098899, recall = 0.006280778074790016.\n",
      "Training on epoch 107 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09263157894736838, recall = 0.008150218036151628.\n",
      "Training on epoch 107 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0835164835164835, recall = 0.007828125012936065.\n",
      "Training on epoch 107 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10531914893617018, recall = 0.008501036233249252.\n",
      "Training on epoch 107 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.1020833333333333, recall = 0.007108190419592749.\n",
      "Training on epoch 107 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.0929292929292929, recall = 0.007643641039206658.\n",
      "\n",
      "Training on 107 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08699999999999995, recall = 0.007436296788066125.\n",
      "\n",
      "Training on the 108 epoch\n",
      "Training on epoch 108 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.008031782259847742.\n",
      "Training on epoch 108 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07934782608695652, recall = 0.004678808811191373.\n",
      "Training on epoch 108 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07052631578947369, recall = 0.0053516424392120645.\n",
      "Training on epoch 108 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09893617021276593, recall = 0.008972459463260472.\n",
      "Training on epoch 108 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08105263157894738, recall = 0.007238915296920611.\n",
      "Training on epoch 108 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08064516129032256, recall = 0.0065049766623674204.\n",
      "Training on epoch 108 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0954022988505747, recall = 0.007193115622599793.\n",
      "Training on epoch 108 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07777777777777777, recall = 0.00793534039302162.\n",
      "\n",
      "Training on 108 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 109 epoch\n",
      "Training on epoch 109 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09890109890109887, recall = 0.008455483881918222.\n",
      "Training on epoch 109 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.090625, recall = 0.00787631938108771.\n",
      "Training on epoch 109 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08571428571428569, recall = 0.0071109168839365855.\n",
      "Training on epoch 109 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08749999999999997, recall = 0.00857252210153913.\n",
      "Training on epoch 109 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08510638297872337, recall = 0.008289635346168236.\n",
      "Training on epoch 109 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09183673469387751, recall = 0.007128722206353181.\n",
      "Training on epoch 109 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08541666666666664, recall = 0.006665240354222366.\n",
      "Training on epoch 109 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09999999999999991, recall = 0.008651471476271077.\n",
      "\n",
      "Training on 109 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.0895, recall = 0.0076087721274747736.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08599999999999997, recall = 0.0073385898138944115.\n",
      "\n",
      "Training on the 110 epoch\n",
      "Training on epoch 110 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0882978723404255, recall = 0.007525608569442191.\n",
      "Training on epoch 110 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.09072164948453605, recall = 0.007422013546932647.\n",
      "Training on epoch 110 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.07912087912087909, recall = 0.007063024105420681.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 110 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09255319148936167, recall = 0.0077755838720121265.\n",
      "Training on epoch 110 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07826086956521736, recall = 0.0069479604508843554.\n",
      "Training on epoch 110 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0904255319148936, recall = 0.0066772611767730245.\n",
      "Training on epoch 110 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.075531914893617, recall = 0.007186785718842239.\n",
      "Training on epoch 110 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.09255319148936166, recall = 0.007343753783893489.\n",
      "\n",
      "Training on 110 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 111 epoch\n",
      "Training on epoch 111 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09230769230769226, recall = 0.008506814954256856.\n",
      "Training on epoch 111 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07912087912087909, recall = 0.00846597315703865.\n",
      "Training on epoch 111 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0747252747252747, recall = 0.0069411692488583025.\n",
      "Training on epoch 111 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07499999999999997, recall = 0.005310616929580747.\n",
      "Training on epoch 111 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.10297029702970291, recall = 0.008431655425551755.\n",
      "Training on epoch 111 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0882978723404255, recall = 0.0074253679777822774.\n",
      "Training on epoch 111 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08817204301075267, recall = 0.0059223538681402324.\n",
      "Training on epoch 111 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09560439560439558, recall = 0.00880961237299671.\n",
      "\n",
      "Training on 111 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999997, recall = 0.007382761482870457.\n",
      "\n",
      "Training on the 112 epoch\n",
      "Training on epoch 112 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09587628865979377, recall = 0.007289280276254633.\n",
      "Training on epoch 112 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08478260869565218, recall = 0.006665241679524763.\n",
      "Training on epoch 112 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.08064516129032254, recall = 0.0066187495970459745.\n",
      "Training on epoch 112 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08876404494382019, recall = 0.006974757474126532.\n",
      "Training on epoch 112 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0797872340425532, recall = 0.005540887375129386.\n",
      "Training on epoch 112 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.07291666666666664, recall = 0.005916438384499315.\n",
      "Training on epoch 112 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08571428571428569, recall = 0.008454014500174672.\n",
      "Training on epoch 112 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09462365591397845, recall = 0.007829461313461112.\n",
      "\n",
      "Training on 112 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.007513225568770324.\n",
      "\n",
      "Training on the 113 epoch\n",
      "Training on epoch 113 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09393939393939393, recall = 0.007639888385409399.\n",
      "Training on epoch 113 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.10102040816326525, recall = 0.006859853567327912.\n",
      "Training on epoch 113 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09468085106382976, recall = 0.008857811259169167.\n",
      "Training on epoch 113 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.083695652173913, recall = 0.00902539581140971.\n",
      "Training on epoch 113 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08461538461538458, recall = 0.0072070153137092936.\n",
      "Training on epoch 113 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08404255319148936, recall = 0.008497873568550661.\n",
      "Training on epoch 113 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.11165048543689317, recall = 0.0083517999290019.\n",
      "Training on epoch 113 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09569892473118279, recall = 0.007930143103099776.\n",
      "\n",
      "Training on 113 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 114 epoch\n",
      "Training on epoch 114 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08735632183908042, recall = 0.006991504805410445.\n",
      "Training on epoch 114 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08514851485148513, recall = 0.006766850606873268.\n",
      "Training on epoch 114 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09603960396039599, recall = 0.007173996874405162.\n",
      "Training on epoch 114 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08415841584158411, recall = 0.009001432486004846.\n",
      "Training on epoch 114 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.09148936170212764, recall = 0.007230147331068725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 114 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09361702127659573, recall = 0.008608719613954203.\n",
      "Training on epoch 114 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07959183673469387, recall = 0.006356696142699632.\n",
      "Training on epoch 114 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08659793814432987, recall = 0.007267176719565832.\n",
      "\n",
      "Training on 114 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999991, recall = 0.007534500282814581.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 115 epoch\n",
      "Training on epoch 115 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09354838709677413, recall = 0.005957113244373879.\n",
      "Training on epoch 115 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10199999999999992, recall = 0.008648910181541595.\n",
      "Training on epoch 115 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09130434782608696, recall = 0.007708664491180866.\n",
      "Training on epoch 115 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0891304347826087, recall = 0.006726425232722872.\n",
      "Training on epoch 115 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09555555555555552, recall = 0.010236836848784896.\n",
      "Training on epoch 115 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08437499999999999, recall = 0.0065669704678565375.\n",
      "Training on epoch 115 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08736842105263155, recall = 0.007036165335419545.\n",
      "Training on epoch 115 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08383838383838382, recall = 0.0071722520354192765.\n",
      "\n",
      "Training on 115 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 116 epoch\n",
      "Training on epoch 116 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.07826086956521736, recall = 0.008513424341854772.\n",
      "Training on epoch 116 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09684210526315785, recall = 0.007417373426814043.\n",
      "Training on epoch 116 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08736842105263155, recall = 0.007263240595167644.\n",
      "Training on epoch 116 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.06999999999999998, recall = 0.00726637471325864.\n",
      "Training on epoch 116 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0909090909090909, recall = 0.009323861216876983.\n",
      "Training on epoch 116 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0833333333333333, recall = 0.007272819044712894.\n",
      "Training on epoch 116 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08085106382978721, recall = 0.006523342887703705.\n",
      "Training on epoch 116 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09687499999999998, recall = 0.008506220772630094.\n",
      "\n",
      "Training on 116 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474772.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 117 epoch\n",
      "Training on epoch 117 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07604166666666663, recall = 0.004856257567788274.\n",
      "Training on epoch 117 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09032258064516124, recall = 0.009735326585077702.\n",
      "Training on epoch 117 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09191919191919186, recall = 0.007893097275967896.\n",
      "Training on epoch 117 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07872340425531911, recall = 0.00825473962741793.\n",
      "Training on epoch 117 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07272727272727271, recall = 0.00695264131684362.\n",
      "Training on epoch 117 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10215053763440861, recall = 0.007980084071203502.\n",
      "Training on epoch 117 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.0917525773195876, recall = 0.007962807917199784.\n",
      "Training on epoch 117 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09462365591397846, recall = 0.0082132972029968.\n",
      "\n",
      "Training on 117 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08699999999999994, recall = 0.0074437895164778615.\n",
      "\n",
      "Training on the 118 epoch\n",
      "Training on epoch 118 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08899999999999997, recall = 0.008382720062629067.\n",
      "Training on epoch 118 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08586956521739128, recall = 0.007910310316382643.\n",
      "Training on epoch 118 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08988764044943816, recall = 0.006074081745892387.\n",
      "Training on epoch 118 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0927835051546391, recall = 0.007074758163962983.\n",
      "Training on epoch 118 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09347826086956519, recall = 0.006282534471371941.\n",
      "Training on epoch 118 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09166666666666663, recall = 0.007467013611623503.\n",
      "Training on epoch 118 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07263157894736842, recall = 0.0070613754030349404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 118 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08131868131868131, recall = 0.00595492750132847.\n",
      "\n",
      "Training on 118 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 119 epoch\n",
      "Training on epoch 119 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08799999999999994, recall = 0.008356402993738103.\n",
      "Training on epoch 119 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09687499999999995, recall = 0.007488658176682143.\n",
      "Training on epoch 119 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08494623655913978, recall = 0.006872337430053836.\n",
      "Training on epoch 119 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08041237113402058, recall = 0.007301027531369105.\n",
      "Training on epoch 119 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.1010416666666666, recall = 0.007237560734949256.\n",
      "Training on epoch 119 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08645833333333329, recall = 0.007852613635636817.\n",
      "Training on epoch 119 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09072164948453605, recall = 0.007313503087079833.\n",
      "Training on epoch 119 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0934065934065934, recall = 0.007696829125785912.\n",
      "\n",
      "Training on 119 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474773.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 120 epoch\n",
      "Training on epoch 120 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08556701030927832, recall = 0.007716456981463036.\n",
      "Training on epoch 120 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08924731182795698, recall = 0.0066997117365540215.\n",
      "Training on epoch 120 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09479166666666665, recall = 0.007002857185591437.\n",
      "Training on epoch 120 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08041237113402058, recall = 0.006874794850483999.\n",
      "Training on epoch 120 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09239130434782605, recall = 0.008823988088391004.\n",
      "Training on epoch 120 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08415841584158412, recall = 0.00786820911275817.\n",
      "Training on epoch 120 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07422680412371131, recall = 0.007134875286524044.\n",
      "Training on epoch 120 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0928571428571428, recall = 0.008077920706381353.\n",
      "\n",
      "Training on 120 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 121 epoch\n",
      "Training on epoch 121 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.11098901098901097, recall = 0.009577419401435026.\n",
      "Training on epoch 121 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.1063829787234042, recall = 0.008612895344578455.\n",
      "Training on epoch 121 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08124999999999999, recall = 0.006290239036681474.\n",
      "Training on epoch 121 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07717391304347823, recall = 0.005956324749986989.\n",
      "Training on epoch 121 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09797979797979792, recall = 0.0070010823405141885.\n",
      "Training on epoch 121 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0863157894736842, recall = 0.007578052335924736.\n",
      "Training on epoch 121 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09687499999999998, recall = 0.00781974014902313.\n",
      "Training on epoch 121 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.0916666666666666, recall = 0.007316908457344555.\n",
      "\n",
      "Training on 121 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.0885, recall = 0.007534500282814585.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08649999999999997, recall = 0.007432408312781599.\n",
      "\n",
      "Training on the 122 epoch\n",
      "Training on epoch 122 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08484848484848481, recall = 0.008149020266346443.\n",
      "Training on epoch 122 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09886363636363633, recall = 0.008985079459911895.\n",
      "Training on epoch 122 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09673913043478258, recall = 0.007417190026800178.\n",
      "Training on epoch 122 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08681318681318677, recall = 0.009526373513971903.\n",
      "Training on epoch 122 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.08602150537634405, recall = 0.007797306617368728.\n",
      "Training on epoch 122 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08686868686868685, recall = 0.007181622598160689.\n",
      "Training on epoch 122 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0845360824742268, recall = 0.005896681245574925.\n",
      "Training on epoch 122 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10329670329670325, recall = 0.009154408779389011.\n",
      "\n",
      "Training on 122 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.0889999999999999, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 123 epoch\n",
      "Training on epoch 123 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09120879120879118, recall = 0.008209775115113649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 123 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.1063829787234042, recall = 0.007229029409043209.\n",
      "Training on epoch 123 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.007451549754507902.\n",
      "Training on epoch 123 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09285714285714286, recall = 0.008153055095547618.\n",
      "Training on epoch 123 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08999999999999998, recall = 0.00832594222149229.\n",
      "Training on epoch 123 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08723404255319146, recall = 0.006117031857649139.\n",
      "Training on epoch 123 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.08510638297872337, recall = 0.006614455091238638.\n",
      "Training on epoch 123 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09565217391304347, recall = 0.008014954562825747.\n",
      "\n",
      "Training on 123 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999994, recall = 0.007468239394228471.\n",
      "\n",
      "Training on the 124 epoch\n",
      "Training on epoch 124 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0821052631578947, recall = 0.008010634420492036.\n",
      "Training on epoch 124 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08736842105263157, recall = 0.00965439837272802.\n",
      "Training on epoch 124 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08620689655172412, recall = 0.007055782405076245.\n",
      "Training on epoch 124 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09599999999999996, recall = 0.007384405711267606.\n",
      "Training on epoch 124 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0791208791208791, recall = 0.006194591413464895.\n",
      "Training on epoch 124 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07872340425531914, recall = 0.006584974375420092.\n",
      "Training on epoch 124 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.096875, recall = 0.007849323993418667.\n",
      "Training on epoch 124 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07956989247311826, recall = 0.006410995184345593.\n",
      "\n",
      "Training on 124 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 125 epoch\n",
      "Training on epoch 125 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08061224489795916, recall = 0.007306057497319771.\n",
      "Training on epoch 125 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0895833333333333, recall = 0.00614311949216981.\n",
      "Training on epoch 125 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07916666666666664, recall = 0.006452653143937888.\n",
      "Training on epoch 125 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09578947368421051, recall = 0.00853247703458367.\n",
      "Training on epoch 125 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09285714285714283, recall = 0.006837143658574074.\n",
      "Training on epoch 125 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08068181818181816, recall = 0.0064301752177785216.\n",
      "Training on epoch 125 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.08131868131868131, recall = 0.007238854388766152.\n",
      "Training on epoch 125 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0784090909090909, recall = 0.00649741538533164.\n",
      "\n",
      "Training on 125 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 126 epoch\n",
      "Training on epoch 126 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.007974758571321345.\n",
      "Training on epoch 126 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.10222222222222217, recall = 0.007745391533494.\n",
      "Training on epoch 126 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08936170212765952, recall = 0.00798546966442603.\n",
      "Training on epoch 126 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08541666666666663, recall = 0.008762876829243172.\n",
      "Training on epoch 126 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08555555555555557, recall = 0.007200065171968257.\n",
      "Training on epoch 126 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08645833333333329, recall = 0.007619094267374012.\n",
      "Training on epoch 126 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08777777777777773, recall = 0.006402222139270703.\n",
      "Training on epoch 126 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08265306122448976, recall = 0.007812773990647228.\n",
      "\n",
      "Training on 126 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08749999999999991, recall = 0.007481452539845906.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 127 epoch\n",
      "Training on epoch 127 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07857142857142857, recall = 0.006850100255390162.\n",
      "Training on epoch 127 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0742268041237113, recall = 0.0075876127342938094.\n",
      "Training on epoch 127 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08666666666666666, recall = 0.007503281852452806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 127 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09354838709677418, recall = 0.00855575670871234.\n",
      "Training on epoch 127 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07604166666666665, recall = 0.007714149127605736.\n",
      "Training on epoch 127 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07368421052631577, recall = 0.007429452259362975.\n",
      "Training on epoch 127 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09888888888888887, recall = 0.006090105401153398.\n",
      "Training on epoch 127 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.09130434782608692, recall = 0.007252878526486419.\n",
      "\n",
      "Training on 127 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999997, recall = 0.007456858190532209.\n",
      "\n",
      "Training on the 128 epoch\n",
      "Training on epoch 128 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09793814432989685, recall = 0.00803975664945935.\n",
      "Training on epoch 128 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0835164835164835, recall = 0.00615377030713531.\n",
      "Training on epoch 128 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0864583333333333, recall = 0.007634822449616851.\n",
      "Training on epoch 128 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08695652173913042, recall = 0.007522248497278521.\n",
      "Training on epoch 128 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07422680412371131, recall = 0.0063459220240619525.\n",
      "Training on epoch 128 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.10106382978723402, recall = 0.007615504714484221.\n",
      "Training on epoch 128 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08749999999999998, recall = 0.006977636476597571.\n",
      "Training on epoch 128 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.1033333333333333, recall = 0.009476171233594526.\n",
      "\n",
      "Training on 128 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08849999999999997, recall = 0.0075545651647039224.\n",
      "\n",
      "Training on the 129 epoch\n",
      "Training on epoch 129 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.10631578947368411, recall = 0.008041596235371.\n",
      "Training on epoch 129 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08543689320388348, recall = 0.0073620809150585585.\n",
      "Training on epoch 129 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0868131868131868, recall = 0.007188234291366585.\n",
      "Training on epoch 129 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09120879120879118, recall = 0.007277558033709866.\n",
      "Training on epoch 129 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08709677419354833, recall = 0.008160495833890558.\n",
      "Training on epoch 129 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08571428571428569, recall = 0.007698370539616451.\n",
      "Training on epoch 129 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09101123595505617, recall = 0.00670261332553233.\n",
      "Training on epoch 129 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09599999999999996, recall = 0.007950804086040923.\n",
      "\n",
      "Training on 129 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999997, recall = 0.007347110302180373.\n",
      "\n",
      "Training on the 130 epoch\n",
      "Training on epoch 130 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0826086956521739, recall = 0.00688611412156178.\n",
      "Training on epoch 130 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08799999999999995, recall = 0.007483612952789345.\n",
      "Training on epoch 130 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08799999999999995, recall = 0.009224755843242161.\n",
      "Training on epoch 130 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09042553191489358, recall = 0.006569395706157872.\n",
      "Training on epoch 130 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09333333333333328, recall = 0.00808861806486353.\n",
      "Training on epoch 130 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09789473684210523, recall = 0.006135541629855309.\n",
      "Training on epoch 130 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0903846153846153, recall = 0.007964161425045154.\n",
      "Training on epoch 130 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.06813186813186814, recall = 0.0060730429675608525.\n",
      "\n",
      "Training on 130 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08649999999999995, recall = 0.007416053873086368.\n",
      "\n",
      "Training on the 131 epoch\n",
      "Training on epoch 131 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.096078431372549, recall = 0.007576943136473374.\n",
      "Training on epoch 131 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09468085106382977, recall = 0.006023427222446506.\n",
      "Training on epoch 131 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.10206185567010306, recall = 0.008305505691408192.\n",
      "Training on epoch 131 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08314606741573033, recall = 0.007687645905732666.\n",
      "Training on epoch 131 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07547169811320754, recall = 0.007359437908798192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 131 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0933333333333333, recall = 0.007788987191259137.\n",
      "Training on epoch 131 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08863636363636364, recall = 0.0058216840654288365.\n",
      "Training on epoch 131 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09191919191919189, recall = 0.00806003793998644.\n",
      "\n",
      "Training on 131 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 132 epoch\n",
      "Training on epoch 132 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693178, and regularization loss is 3.1e-05.\n",
      " Top K precision = 0.0845360824742268, recall = 0.0074382527605831965.\n",
      "Training on epoch 132 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09595959595959591, recall = 0.007064414731645109.\n",
      "Training on epoch 132 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07799999999999999, recall = 0.006244935068045876.\n",
      "Training on epoch 132 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08453608247422678, recall = 0.007780357081323986.\n",
      "Training on epoch 132 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08080808080808079, recall = 0.006817889749970032.\n",
      "Training on epoch 132 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07499999999999998, recall = 0.0055470704861885515.\n",
      "Training on epoch 132 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08673469387755098, recall = 0.006375008533413028.\n",
      "Training on epoch 132 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08736842105263153, recall = 0.007862016102342611.\n",
      "\n",
      "Training on 132 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 133 epoch\n",
      "Training on epoch 133 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08111111111111106, recall = 0.00932195234540836.\n",
      "Training on epoch 133 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09010989010989008, recall = 0.007777711992579561.\n",
      "Training on epoch 133 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08666666666666667, recall = 0.0073856605786101915.\n",
      "Training on epoch 133 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09285714285714282, recall = 0.007518121569253277.\n",
      "Training on epoch 133 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07878787878787875, recall = 0.0060304210505393654.\n",
      "Training on epoch 133 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.0852631578947368, recall = 0.007086618055045853.\n",
      "Training on epoch 133 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09795918367346934, recall = 0.00832401695446169.\n",
      "Training on epoch 133 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
      " Top K precision = 0.09340659340659341, recall = 0.008043269038938091.\n",
      "\n",
      "Training on 133 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 134 epoch\n",
      "Training on epoch 134 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08265306122448973, recall = 0.007826142117183705.\n",
      "Training on epoch 134 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09278350515463914, recall = 0.007479909251170283.\n",
      "Training on epoch 134 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08775510204081627, recall = 0.007045320164235971.\n",
      "Training on epoch 134 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08842105263157896, recall = 0.006813716427236489.\n",
      "Training on epoch 134 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09673913043478259, recall = 0.008232680633407185.\n",
      "Training on epoch 134 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09387755102040814, recall = 0.0068071703669286485.\n",
      "Training on epoch 134 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
      " Top K precision = 0.08043478260869562, recall = 0.007306936085249284.\n",
      "Training on epoch 134 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07216494845360823, recall = 0.004850249356485742.\n",
      "\n",
      "Training on 134 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999994, recall = 0.007468239394228471.\n",
      "\n",
      "Training on the 135 epoch\n",
      "Training on epoch 135 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.10103092783505149, recall = 0.006415138347861027.\n",
      "Training on epoch 135 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08599999999999998, recall = 0.0071443605875011725.\n",
      "Training on epoch 135 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07788461538461534, recall = 0.007944533736368572.\n",
      "Training on epoch 135 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09255319148936166, recall = 0.00669805116016121.\n",
      "Training on epoch 135 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693185, and regularization loss is 3.7e-05.\n",
      " Top K precision = 0.09081632653061222, recall = 0.006926777038863823.\n",
      "Training on epoch 135 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09894736842105263, recall = 0.008732623065095256.\n",
      "Training on epoch 135 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10412371134020615, recall = 0.00779204330345885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 135 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.0947368421052631, recall = 0.008328656556640102.\n",
      "\n",
      "Training on 135 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 136 epoch\n",
      "Training on epoch 136 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.11041666666666666, recall = 0.008458368704646215.\n",
      "Training on epoch 136 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0829787234042553, recall = 0.007538770409860212.\n",
      "Training on epoch 136 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08124999999999998, recall = 0.006191738700675004.\n",
      "Training on epoch 136 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07959183673469385, recall = 0.007058079545950858.\n",
      "Training on epoch 136 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.10707070707070701, recall = 0.009163158707685541.\n",
      "Training on epoch 136 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09247311827956985, recall = 0.008517240739656342.\n",
      "Training on epoch 136 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07472527472527474, recall = 0.0075721139338639975.\n",
      "Training on epoch 136 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.07526881720430104, recall = 0.005568615034581342.\n",
      "\n",
      "Training on 136 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 137 epoch\n",
      "Training on epoch 137 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.10224719101123592, recall = 0.008663482248418394.\n",
      "Training on epoch 137 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08640776699029125, recall = 0.007566418020995381.\n",
      "Training on epoch 137 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.07899999999999997, recall = 0.006724883856862457.\n",
      "Training on epoch 137 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09565217391304347, recall = 0.00838244959286028.\n",
      "Training on epoch 137 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09666666666666662, recall = 0.008340016173928141.\n",
      "Training on epoch 137 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09166666666666662, recall = 0.006140177841942453.\n",
      "Training on epoch 137 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08247422680412368, recall = 0.007075300246706437.\n",
      "Training on epoch 137 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09687499999999995, recall = 0.008826417276089018.\n",
      "\n",
      "Training on 137 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08900000000000001, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 138 epoch\n",
      "Training on epoch 138 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07575757575757573, recall = 0.006714007875031714.\n",
      "Training on epoch 138 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0896907216494845, recall = 0.006944841996075948.\n",
      "Training on epoch 138 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08163265306122447, recall = 0.007077963906884837.\n",
      "Training on epoch 138 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08876404494382019, recall = 0.007988188719004755.\n",
      "Training on epoch 138 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07765957446808505, recall = 0.008493562415827936.\n",
      "Training on epoch 138 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07999999999999997, recall = 0.00718944951383894.\n",
      "Training on epoch 138 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08865979381443295, recall = 0.0075084619498480476.\n",
      "Training on epoch 138 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08461538461538459, recall = 0.007201122386472658.\n",
      "\n",
      "Training on 138 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999997, recall = 0.0075725083912110405.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999993, recall = 0.007453295219899915.\n",
      "\n",
      "Training on the 139 epoch\n",
      "Training on epoch 139 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08791208791208788, recall = 0.00857609057421989.\n",
      "Training on epoch 139 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08199999999999996, recall = 0.0067407226777762485.\n",
      "Training on epoch 139 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08202247191011236, recall = 0.007848286920121038.\n",
      "Training on epoch 139 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0917525773195876, recall = 0.007316671463593193.\n",
      "Training on epoch 139 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0857142857142857, recall = 0.009218042527778013.\n",
      "Training on epoch 139 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09499999999999993, recall = 0.008052671283887347.\n",
      "Training on epoch 139 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0882978723404255, recall = 0.007599351663588229.\n",
      "Training on epoch 139 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09462365591397848, recall = 0.007548272608796349.\n",
      "\n",
      "Training on 139 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 140 epoch\n",
      "Training on epoch 140 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08620689655172412, recall = 0.0058405802053007275.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 140 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09690721649484531, recall = 0.006967283772894756.\n",
      "Training on epoch 140 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10396039603960393, recall = 0.007517438498474111.\n",
      "Training on epoch 140 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07789473684210528, recall = 0.005501968171005299.\n",
      "Training on epoch 140 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09263157894736838, recall = 0.008343581452929424.\n",
      "Training on epoch 140 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09555555555555552, recall = 0.007152836920586156.\n",
      "Training on epoch 140 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07325581395348837, recall = 0.007406752960332722.\n",
      "Training on epoch 140 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09479166666666665, recall = 0.007167613523738129.\n",
      "\n",
      "Training on 140 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 141 epoch\n",
      "Training on epoch 141 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0895833333333333, recall = 0.007638344335533183.\n",
      "Training on epoch 141 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.08437499999999998, recall = 0.006402603292905765.\n",
      "Training on epoch 141 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.007504436703748273.\n",
      "Training on epoch 141 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10215053763440857, recall = 0.009647366346963079.\n",
      "Training on epoch 141 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0869565217391304, recall = 0.00740918979322768.\n",
      "Training on epoch 141 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08415841584158414, recall = 0.007809592117531614.\n",
      "Training on epoch 141 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09062499999999996, recall = 0.00800048841401887.\n",
      "Training on epoch 141 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.11368421052631572, recall = 0.008441051691943806.\n",
      "\n",
      "Training on 141 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.0885, recall = 0.007538851808749674.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 142 epoch\n",
      "Training on epoch 142 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08989898989898985, recall = 0.008116134990243315.\n",
      "Training on epoch 142 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09560439560439558, recall = 0.005702546998192806.\n",
      "Training on epoch 142 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08111111111111108, recall = 0.008501661339630671.\n",
      "Training on epoch 142 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.097752808988764, recall = 0.0071927590200779766.\n",
      "Training on epoch 142 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0858695652173913, recall = 0.006877038488278393.\n",
      "Training on epoch 142 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0769230769230769, recall = 0.007616363828474048.\n",
      "Training on epoch 142 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07419354838709677, recall = 0.006122849484133902.\n",
      "Training on epoch 142 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09411764705882351, recall = 0.006677736696091711.\n",
      "\n",
      "Training on 142 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474773.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 143 epoch\n",
      "Training on epoch 143 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.10430107526881714, recall = 0.009378460119755133.\n",
      "Training on epoch 143 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.007224655554172099.\n",
      "Training on epoch 143 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08383838383838381, recall = 0.007755812230127772.\n",
      "Training on epoch 143 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09892473118279566, recall = 0.0070171440105109605.\n",
      "Training on epoch 143 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09148936170212764, recall = 0.008026082726619567.\n",
      "Training on epoch 143 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09890109890109887, recall = 0.007931768903127957.\n",
      "Training on epoch 143 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09560439560439558, recall = 0.007605052081025723.\n",
      "Training on epoch 143 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07916666666666664, recall = 0.007887764014781416.\n",
      "\n",
      "Training on 143 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075790150424545335.\n",
      "\n",
      "Training on the 144 epoch\n",
      "Training on epoch 144 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09899999999999999, recall = 0.00821034989366971.\n",
      "Training on epoch 144 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.2e-05.\n",
      " Top K precision = 0.06263736263736262, recall = 0.006054446490042423.\n",
      "Training on epoch 144 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.0938775510204081, recall = 0.007505404564939278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 144 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08602150537634407, recall = 0.006984667322129887.\n",
      "Training on epoch 144 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08089887640449436, recall = 0.006979735132320849.\n",
      "Training on epoch 144 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07403846153846151, recall = 0.006136022942904541.\n",
      "Training on epoch 144 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08543689320388345, recall = 0.007839757435297691.\n",
      "Training on epoch 144 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08556701030927832, recall = 0.006460880375212974.\n",
      "\n",
      "Training on 144 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 145 epoch\n",
      "Training on epoch 145 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08556701030927834, recall = 0.006634667883466706.\n",
      "Training on epoch 145 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10229885057471261, recall = 0.006792630071295351.\n",
      "Training on epoch 145 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09578947368421048, recall = 0.007146638403000978.\n",
      "Training on epoch 145 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09166666666666662, recall = 0.006981434506217362.\n",
      "Training on epoch 145 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07653061224489795, recall = 0.006152435379552094.\n",
      "Training on epoch 145 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.060215053763440864, recall = 0.006712623879537791.\n",
      "Training on epoch 145 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08421052631578943, recall = 0.00587968015673268.\n",
      "Training on epoch 145 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.0813725490196078, recall = 0.008936545470525307.\n",
      "\n",
      "Training on 145 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 146 epoch\n",
      "Training on epoch 146 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08865979381443292, recall = 0.007693103401990944.\n",
      "Training on epoch 146 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08279569892473117, recall = 0.0089099135424402.\n",
      "Training on epoch 146 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09052631578947366, recall = 0.007596408481189901.\n",
      "Training on epoch 146 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07045454545454545, recall = 0.00641292777066392.\n",
      "Training on epoch 146 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08541666666666664, recall = 0.007453541146294384.\n",
      "Training on epoch 146 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08137254901960783, recall = 0.008344538299464738.\n",
      "Training on epoch 146 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.1, recall = 0.007578049982697682.\n",
      "Training on epoch 146 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09897959183673463, recall = 0.007757258391475448.\n",
      "\n",
      "Training on 146 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999997, recall = 0.007579519015441578.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08699999999999995, recall = 0.0074361113025654055.\n",
      "\n",
      "Training on the 147 epoch\n",
      "Training on epoch 147 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09139784946236557, recall = 0.009745123271215114.\n",
      "Training on epoch 147 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.08979591836734693, recall = 0.007253788351150349.\n",
      "Training on epoch 147 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09354838709677417, recall = 0.007959703759921857.\n",
      "Training on epoch 147 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09032258064516124, recall = 0.007487014705134277.\n",
      "Training on epoch 147 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09081632653061221, recall = 0.007853982391101612.\n",
      "Training on epoch 147 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09684210526315785, recall = 0.007941546167301338.\n",
      "Training on epoch 147 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07954545454545452, recall = 0.0072998414006562725.\n",
      "Training on epoch 147 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08854166666666667, recall = 0.006619509157734941.\n",
      "\n",
      "Training on 147 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 148 epoch\n",
      "Training on epoch 148 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.1030927835051546, recall = 0.008986010331222637.\n",
      "Training on epoch 148 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08089887640449436, recall = 0.007107190569899643.\n",
      "Training on epoch 148 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.10106382978723397, recall = 0.009597412003809107.\n",
      "Training on epoch 148 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07821782178217819, recall = 0.0067183709855124394.\n",
      "Training on epoch 148 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09578947368421045, recall = 0.006499506093216345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 148 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08210526315789472, recall = 0.0083299019501005.\n",
      "Training on epoch 148 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09468085106382973, recall = 0.008654713611089047.\n",
      "Training on epoch 148 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.10222222222222216, recall = 0.006343349908061913.\n",
      "\n",
      "Training on 148 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0076694864131890625.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 149 epoch\n",
      "Training on epoch 149 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08526315789473683, recall = 0.007091619435818281.\n",
      "Training on epoch 149 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09361702127659571, recall = 0.008494281579848093.\n",
      "Training on epoch 149 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10319148936170207, recall = 0.008768113713095478.\n",
      "Training on epoch 149 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07978723404255315, recall = 0.007527337370769585.\n",
      "Training on epoch 149 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09325842696629212, recall = 0.008130154583178882.\n",
      "Training on epoch 149 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09213483146067412, recall = 0.006184217190507006.\n",
      "Training on epoch 149 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.1052083333333333, recall = 0.009064985514225044.\n",
      "Training on epoch 149 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08924731182795698, recall = 0.008518631743560823.\n",
      "\n",
      "Training on 149 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 150 epoch\n",
      "Training on epoch 150 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08695652173913039, recall = 0.006849662545846108.\n",
      "Training on epoch 150 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08105263157894735, recall = 0.006780288800909698.\n",
      "Training on epoch 150 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08105263157894736, recall = 0.008180610962079076.\n",
      "Training on epoch 150 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09340659340659337, recall = 0.008465026356197742.\n",
      "Training on epoch 150 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09148936170212764, recall = 0.007300231192357816.\n",
      "Training on epoch 150 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08152173913043476, recall = 0.0060818955381565076.\n",
      "Training on epoch 150 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08804347826086956, recall = 0.00632854960663422.\n",
      "Training on epoch 150 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08829787234042553, recall = 0.00837181409312401.\n",
      "\n",
      "Training on 150 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 151 epoch\n",
      "Training on epoch 151 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0928571428571428, recall = 0.007306821600784453.\n",
      "Training on epoch 151 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09892473118279567, recall = 0.008714440265055488.\n",
      "Training on epoch 151 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09450549450549449, recall = 0.008838761563822057.\n",
      "Training on epoch 151 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0833333333333333, recall = 0.006564684566869412.\n",
      "Training on epoch 151 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.009071459534856451.\n",
      "Training on epoch 151 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09126213592233007, recall = 0.00719959925749118.\n",
      "Training on epoch 151 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09368421052631581, recall = 0.006728197385558615.\n",
      "Training on epoch 151 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09032258064516126, recall = 0.007816202783459607.\n",
      "\n",
      "Training on 151 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.088, recall = 0.007534322249724167.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 152 epoch\n",
      "Training on epoch 152 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08695652173913042, recall = 0.006589981029043463.\n",
      "Training on epoch 152 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08571428571428573, recall = 0.006579203419076168.\n",
      "Training on epoch 152 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.0979797979797979, recall = 0.007423807151122628.\n",
      "Training on epoch 152 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.1041237113402062, recall = 0.008887187926584005.\n",
      "Training on epoch 152 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08431372549019606, recall = 0.007938009613142404.\n",
      "Training on epoch 152 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10108695652173907, recall = 0.00805146086072474.\n",
      "Training on epoch 152 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09591836734693875, recall = 0.008819282263531148.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 152 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09883720930232556, recall = 0.007567298392209105.\n",
      "\n",
      "Training on 152 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 153 epoch\n",
      "Training on epoch 153 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09139784946236557, recall = 0.006237106393511318.\n",
      "Training on epoch 153 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09897959183673465, recall = 0.0071100206848288515.\n",
      "Training on epoch 153 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.07731958762886597, recall = 0.005830708607513822.\n",
      "Training on epoch 153 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07765957446808508, recall = 0.007083560828950067.\n",
      "Training on epoch 153 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.10102040816326527, recall = 0.008394216493489702.\n",
      "Training on epoch 153 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08105263157894736, recall = 0.0070317397338495085.\n",
      "Training on epoch 153 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.08478260869565216, recall = 0.006487768475071576.\n",
      "Training on epoch 153 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08924731182795696, recall = 0.007902522723008813.\n",
      "\n",
      "Training on 153 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999995, recall = 0.007440503750836979.\n",
      "\n",
      "Training on the 154 epoch\n",
      "Training on epoch 154 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09052631578947365, recall = 0.006387059897983115.\n",
      "Training on epoch 154 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08061224489795915, recall = 0.006704834000170297.\n",
      "Training on epoch 154 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09120879120879116, recall = 0.00892231302353296.\n",
      "Training on epoch 154 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.07978723404255318, recall = 0.005805411088236802.\n",
      "Training on epoch 154 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07613636363636361, recall = 0.007575232997464282.\n",
      "Training on epoch 154 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08659793814432984, recall = 0.0081964391312404.\n",
      "Training on epoch 154 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.0908163265306122, recall = 0.007851371077206357.\n",
      "Training on epoch 154 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08775510204081632, recall = 0.006625748356718079.\n",
      "\n",
      "Training on 154 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 155 epoch\n",
      "Training on epoch 155 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09438202247191008, recall = 0.008357505327039737.\n",
      "Training on epoch 155 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08369565217391303, recall = 0.005843623101142287.\n",
      "Training on epoch 155 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07549019607843135, recall = 0.007598926317909128.\n",
      "Training on epoch 155 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08297872340425531, recall = 0.008513915657685816.\n",
      "Training on epoch 155 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08315789473684207, recall = 0.006952773632284106.\n",
      "Training on epoch 155 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09052631578947362, recall = 0.008027614721032916.\n",
      "Training on epoch 155 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09130434782608692, recall = 0.007710365726294683.\n",
      "Training on epoch 155 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09450549450549449, recall = 0.008628197377512014.\n",
      "\n",
      "Training on 155 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08900000000000001, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 156 epoch\n",
      "Training on epoch 156 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09509803921568623, recall = 0.0071722100677599505.\n",
      "Training on epoch 156 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.07789473684210524, recall = 0.008284144284807001.\n",
      "Training on epoch 156 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07777777777777777, recall = 0.00793225938316462.\n",
      "Training on epoch 156 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08461538461538456, recall = 0.007995369118841945.\n",
      "Training on epoch 156 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0714285714285714, recall = 0.00652749241045492.\n",
      "Training on epoch 156 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0895833333333333, recall = 0.008280405570660218.\n",
      "Training on epoch 156 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09896907216494845, recall = 0.008168308305786697.\n",
      "Training on epoch 156 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08829787234042548, recall = 0.007913679352990602.\n",
      "\n",
      "Training on 156 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999994, recall = 0.007468239394228471.\n",
      "\n",
      "Training on the 157 epoch\n",
      "Training on epoch 157 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08453608247422678, recall = 0.007905430646412408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 157 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.10515463917525769, recall = 0.007800359113814923.\n",
      "Training on epoch 157 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.10769230769230764, recall = 0.00831847613261926.\n",
      "Training on epoch 157 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09591836734693877, recall = 0.007634906324695198.\n",
      "Training on epoch 157 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08571428571428569, recall = 0.006859577582486247.\n",
      "Training on epoch 157 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08383838383838382, recall = 0.005649064120610514.\n",
      "Training on epoch 157 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07959183673469385, recall = 0.006861960324049081.\n",
      "Training on epoch 157 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.06703296703296702, recall = 0.006225121465440849.\n",
      "\n",
      "Training on 157 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 158 epoch\n",
      "Training on epoch 158 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08787878787878788, recall = 0.007465648685344766.\n",
      "Training on epoch 158 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07956989247311824, recall = 0.006143490462425803.\n",
      "Training on epoch 158 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0864583333333333, recall = 0.009476702737290907.\n",
      "Training on epoch 158 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07934782608695652, recall = 0.006833731066217952.\n",
      "Training on epoch 158 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.086734693877551, recall = 0.008733827880967776.\n",
      "Training on epoch 158 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09306930693069304, recall = 0.007845859279120397.\n",
      "Training on epoch 158 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08854166666666663, recall = 0.006904388211995478.\n",
      "Training on epoch 158 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08144329896907215, recall = 0.007129909370849328.\n",
      "\n",
      "Training on 158 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 159 epoch\n",
      "Training on epoch 159 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08315789473684207, recall = 0.00735014211255076.\n",
      "Training on epoch 159 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07916666666666668, recall = 0.006622562818725308.\n",
      "Training on epoch 159 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09894736842105263, recall = 0.008156892634864552.\n",
      "Training on epoch 159 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.08541666666666664, recall = 0.009171222229946475.\n",
      "Training on epoch 159 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08556701030927832, recall = 0.007636733928559251.\n",
      "Training on epoch 159 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08333333333333329, recall = 0.007651594068492462.\n",
      "Training on epoch 159 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09325842696629211, recall = 0.007619674722067723.\n",
      "Training on epoch 159 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08125, recall = 0.007103376860903436.\n",
      "\n",
      "Training on 159 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 160 epoch\n",
      "Training on epoch 160 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07857142857142857, recall = 0.005593996384560226.\n",
      "Training on epoch 160 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09139784946236555, recall = 0.008231885280777645.\n",
      "Training on epoch 160 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08585858585858584, recall = 0.008488893701797279.\n",
      "Training on epoch 160 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07872340425531911, recall = 0.008087303109842901.\n",
      "Training on epoch 160 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07604166666666663, recall = 0.006824731292447695.\n",
      "Training on epoch 160 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08089887640449435, recall = 0.006384642724716117.\n",
      "Training on epoch 160 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08461538461538462, recall = 0.0073123492592122065.\n",
      "Training on epoch 160 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0887755102040816, recall = 0.008001682986318322.\n",
      "\n",
      "Training on 160 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 161 epoch\n",
      "Training on epoch 161 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08723404255319145, recall = 0.0072436873219115456.\n",
      "Training on epoch 161 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08651685393258428, recall = 0.00771240702071794.\n",
      "Training on epoch 161 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09278350515463912, recall = 0.00763329255342002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 161 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07204301075268814, recall = 0.006072113272851083.\n",
      "Training on epoch 161 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10599999999999994, recall = 0.008101114181003366.\n",
      "Training on epoch 161 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08762886597938138, recall = 0.007728202256739229.\n",
      "Training on epoch 161 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09693877551020401, recall = 0.009097457343619126.\n",
      "Training on epoch 161 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09999999999999999, recall = 0.006564650832722119.\n",
      "\n",
      "Training on 161 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999994, recall = 0.007715022127474774.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 162 epoch\n",
      "Training on epoch 162 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09072164948453604, recall = 0.00751025655944708.\n",
      "Training on epoch 162 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08076923076923076, recall = 0.0064884905819763755.\n",
      "Training on epoch 162 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09687499999999995, recall = 0.008707740419709481.\n",
      "Training on epoch 162 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09893617021276593, recall = 0.006989350830020601.\n",
      "Training on epoch 162 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08556701030927832, recall = 0.007155208091294648.\n",
      "Training on epoch 162 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08795180722891564, recall = 0.005926529738310437.\n",
      "Training on epoch 162 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.078125, recall = 0.0070297770195192.\n",
      "Training on epoch 162 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.07291666666666662, recall = 0.007366085355537862.\n",
      "\n",
      "Training on 162 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 163 epoch\n",
      "Training on epoch 163 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10107526881720429, recall = 0.00985653640357411.\n",
      "Training on epoch 163 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0789473684210526, recall = 0.007662568250607982.\n",
      "Training on epoch 163 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08854166666666664, recall = 0.006519826115475307.\n",
      "Training on epoch 163 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08265306122448979, recall = 0.006088628501549433.\n",
      "Training on epoch 163 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08936170212765954, recall = 0.008986151822638956.\n",
      "Training on epoch 163 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08421052631578944, recall = 0.0069902915203016395.\n",
      "Training on epoch 163 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08269230769230762, recall = 0.006287966877323891.\n",
      "Training on epoch 163 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08631578947368422, recall = 0.007247538796059774.\n",
      "\n",
      "Training on 163 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08799999999999994, recall = 0.007534322249724164.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 164 epoch\n",
      "Training on epoch 164 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09207920792079205, recall = 0.008080699328512242.\n",
      "Training on epoch 164 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.0916666666666666, recall = 0.008313191555566883.\n",
      "Training on epoch 164 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.1042553191489361, recall = 0.008807707182998026.\n",
      "Training on epoch 164 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08387096774193545, recall = 0.0069331211863032.\n",
      "Training on epoch 164 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0912087912087912, recall = 0.007177680854903884.\n",
      "Training on epoch 164 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.10112359550561792, recall = 0.00812941056355523.\n",
      "Training on epoch 164 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09270833333333332, recall = 0.006589014963051335.\n",
      "Training on epoch 164 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.09775280898876401, recall = 0.008085902253368242.\n",
      "\n",
      "Training on 164 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.007460746665816737.\n",
      "\n",
      "Training on the 165 epoch\n",
      "Training on epoch 165 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.10103092783505149, recall = 0.00932669605431971.\n",
      "Training on epoch 165 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08539325842696628, recall = 0.00755978308840015.\n",
      "Training on epoch 165 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08775510204081628, recall = 0.0069415063566753915.\n",
      "Training on epoch 165 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08387096774193543, recall = 0.007504544049195018.\n",
      "Training on epoch 165 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09052631578947365, recall = 0.009064492101318948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 165 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09000000000000001, recall = 0.006628121823576752.\n",
      "Training on epoch 165 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09166666666666663, recall = 0.006458665014430688.\n",
      "Training on epoch 165 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07912087912087912, recall = 0.005917917465986244.\n",
      "\n",
      "Training on 165 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 166 epoch\n",
      "Training on epoch 166 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0864583333333333, recall = 0.008639702325615265.\n",
      "Training on epoch 166 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09387755102040814, recall = 0.007984005385983633.\n",
      "Training on epoch 166 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09318181818181817, recall = 0.009389713525284525.\n",
      "Training on epoch 166 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09157894736842102, recall = 0.007961688895068998.\n",
      "Training on epoch 166 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07872340425531914, recall = 0.008575717193591568.\n",
      "Training on epoch 166 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09999999999999994, recall = 0.00813694019563005.\n",
      "Training on epoch 166 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09340659340659335, recall = 0.006837990119329864.\n",
      "Training on epoch 166 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0793478260869565, recall = 0.006283614726992016.\n",
      "\n",
      "Training on 166 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08799999999999995, recall = 0.007534322249724163.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08499999999999995, recall = 0.007314139936143801.\n",
      "\n",
      "Training on the 167 epoch\n",
      "Training on epoch 167 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09340659340659337, recall = 0.007750014380226267.\n",
      "Training on epoch 167 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09456521739130434, recall = 0.007356885265397593.\n",
      "Training on epoch 167 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08181818181818179, recall = 0.007004555195852051.\n",
      "Training on epoch 167 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08969072164948451, recall = 0.00720090010005545.\n",
      "Training on epoch 167 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09999999999999995, recall = 0.008751280033550022.\n",
      "Training on epoch 167 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07187500000000001, recall = 0.007514984181946747.\n",
      "Training on epoch 167 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09999999999999998, recall = 0.00806831371012822.\n",
      "Training on epoch 167 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.10106382978723401, recall = 0.009661307612058618.\n",
      "\n",
      "Training on 167 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08999999999999997, recall = 0.007852889774533599.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08999999999999997, recall = 0.007588520745876587.\n",
      "\n",
      "Training on the 168 epoch\n",
      "Training on epoch 168 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09263157894736838, recall = 0.007096759577971795.\n",
      "Training on epoch 168 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07444444444444444, recall = 0.006862155699703338.\n",
      "Training on epoch 168 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0967741935483871, recall = 0.008191730235559346.\n",
      "Training on epoch 168 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08172043010752685, recall = 0.0072570796945090965.\n",
      "Training on epoch 168 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.1e-05.\n",
      " Top K precision = 0.08210526315789472, recall = 0.006406057688279362.\n",
      "Training on epoch 168 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08421052631578943, recall = 0.0070203327153043164.\n",
      "Training on epoch 168 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09062499999999996, recall = 0.009198434378887095.\n",
      "Training on epoch 168 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09599999999999996, recall = 0.007273083769843349.\n",
      "\n",
      "Training on 168 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 169 epoch\n",
      "Training on epoch 169 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08777777777777772, recall = 0.00829794194917046.\n",
      "Training on epoch 169 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08571428571428567, recall = 0.00749260280225653.\n",
      "Training on epoch 169 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.10106382978723402, recall = 0.00886748354177989.\n",
      "Training on epoch 169 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08585858585858586, recall = 0.007633804885345486.\n",
      "Training on epoch 169 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09270833333333332, recall = 0.006313182767230371.\n",
      "Training on epoch 169 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693181, and regularization loss is 3.4e-05.\n",
      " Top K precision = 0.0978260869565217, recall = 0.0074265882644855615.\n",
      "Training on epoch 169 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0923076923076923, recall = 0.008982181271769535.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 169 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09130434782608696, recall = 0.005899427964157711.\n",
      "\n",
      "Training on 169 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 170 epoch\n",
      "Training on epoch 170 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0879120879120879, recall = 0.007103709077832886.\n",
      "Training on epoch 170 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.07659574468085102, recall = 0.00716996358531549.\n",
      "Training on epoch 170 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08043478260869563, recall = 0.005945007088564159.\n",
      "Training on epoch 170 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09191919191919189, recall = 0.006411103406840725.\n",
      "Training on epoch 170 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.07676767676767675, recall = 0.006225212585399075.\n",
      "Training on epoch 170 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08155339805825242, recall = 0.006730244706768241.\n",
      "Training on epoch 170 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09157894736842102, recall = 0.0076657481016023585.\n",
      "Training on epoch 170 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09569892473118274, recall = 0.008355485948793132.\n",
      "\n",
      "Training on 170 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 171 epoch\n",
      "Training on epoch 171 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08499999999999996, recall = 0.006745335808023699.\n",
      "Training on epoch 171 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08163265306122448, recall = 0.00705470355495597.\n",
      "Training on epoch 171 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08585858585858583, recall = 0.009433239000244596.\n",
      "Training on epoch 171 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.10729166666666666, recall = 0.007506721667923715.\n",
      "Training on epoch 171 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.10210526315789469, recall = 0.008191558676546218.\n",
      "Training on epoch 171 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.0914893617021276, recall = 0.0077663331244736.\n",
      "Training on epoch 171 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.0925531914893617, recall = 0.008942332942214977.\n",
      "Training on epoch 171 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.10520833333333329, recall = 0.009143863850125299.\n",
      "\n",
      "Training on 171 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007464432504833269.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 172 epoch\n",
      "Training on epoch 172 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07052631578947367, recall = 0.006110277995975824.\n",
      "Training on epoch 172 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09791666666666664, recall = 0.006555493695553342.\n",
      "Training on epoch 172 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08988764044943817, recall = 0.007321923939495137.\n",
      "Training on epoch 172 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09278350515463918, recall = 0.00839068700250569.\n",
      "Training on epoch 172 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09255319148936166, recall = 0.008175738951157835.\n",
      "Training on epoch 172 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09888888888888886, recall = 0.007899036878020706.\n",
      "Training on epoch 172 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0977272727272727, recall = 0.008282582432234514.\n",
      "Training on epoch 172 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0833333333333333, recall = 0.007254511184691166.\n",
      "\n",
      "Training on 172 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08049999999999993, recall = 0.007020934683827988.\n",
      "\n",
      "Training on the 173 epoch\n",
      "Training on epoch 173 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.10108695652173907, recall = 0.009287267420955939.\n",
      "Training on epoch 173 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.08260869565217391, recall = 0.00677448134681425.\n",
      "Training on epoch 173 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.10444444444444441, recall = 0.008381507746987045.\n",
      "Training on epoch 173 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0927083333333333, recall = 0.00818676483667225.\n",
      "Training on epoch 173 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08210526315789471, recall = 0.007262437951052323.\n",
      "Training on epoch 173 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08315789473684208, recall = 0.006893506082533995.\n",
      "Training on epoch 173 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08315789473684211, recall = 0.006534643200554106.\n",
      "Training on epoch 173 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08191489361702124, recall = 0.007588301034288248.\n",
      "\n",
      "Training on 173 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 174 epoch\n",
      "Training on epoch 174 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08556701030927834, recall = 0.007109664230760955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 174 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.0927083333333333, recall = 0.006779745398425398.\n",
      "Training on epoch 174 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08651685393258425, recall = 0.006998357607733796.\n",
      "Training on epoch 174 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09032258064516127, recall = 0.009679538588898967.\n",
      "Training on epoch 174 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
      " Top K precision = 0.07916666666666665, recall = 0.006534735390836946.\n",
      "Training on epoch 174 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08736842105263153, recall = 0.00664907016369783.\n",
      "Training on epoch 174 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08350515463917524, recall = 0.007075751806164372.\n",
      "Training on epoch 174 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08631578947368418, recall = 0.00798974049184799.\n",
      "\n",
      "Training on 174 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 175 epoch\n",
      "Training on epoch 175 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.09540229885057472, recall = 0.008702305036320586.\n",
      "Training on epoch 175 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.1010416666666666, recall = 0.008154506539832438.\n",
      "Training on epoch 175 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.10309278350515456, recall = 0.008251333011904163.\n",
      "Training on epoch 175 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09157894736842102, recall = 0.008161697215166795.\n",
      "Training on epoch 175 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.10721649484536079, recall = 0.008473550519623885.\n",
      "Training on epoch 175 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09583333333333327, recall = 0.0075406470176941605.\n",
      "Training on epoch 175 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08854166666666667, recall = 0.005680170537368266.\n",
      "Training on epoch 175 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.10666666666666663, recall = 0.008019318816757822.\n",
      "\n",
      "Training on 175 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999994, recall = 0.007464432504833266.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 176 epoch\n",
      "Training on epoch 176 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09222222222222219, recall = 0.008866828413949956.\n",
      "Training on epoch 176 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08989898989898988, recall = 0.007606849711592514.\n",
      "Training on epoch 176 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08191489361702127, recall = 0.007177298699905311.\n",
      "Training on epoch 176 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.0908163265306122, recall = 0.008262705456071377.\n",
      "Training on epoch 176 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07282608695652174, recall = 0.008145226156012762.\n",
      "Training on epoch 176 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
      " Top K precision = 0.09399999999999994, recall = 0.008284659591039214.\n",
      "Training on epoch 176 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08085106382978721, recall = 0.005524238648344086.\n",
      "Training on epoch 176 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08282828282828278, recall = 0.007175311306074937.\n",
      "\n",
      "Training on 176 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999993, recall = 0.007545331267259724.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08749999999999997, recall = 0.007456858190532209.\n",
      "\n",
      "Training on the 177 epoch\n",
      "Training on epoch 177 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09565217391304343, recall = 0.006934140202668024.\n",
      "Training on epoch 177 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09062499999999997, recall = 0.007293703026289223.\n",
      "Training on epoch 177 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.071, recall = 0.006278861220132154.\n",
      "Training on epoch 177 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.07978723404255315, recall = 0.008424219254681693.\n",
      "Training on epoch 177 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09340659340659335, recall = 0.009781476310193955.\n",
      "Training on epoch 177 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09150943396226413, recall = 0.007175889084669584.\n",
      "Training on epoch 177 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08681318681318677, recall = 0.007026397518268285.\n",
      "Training on epoch 177 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07666666666666665, recall = 0.007133960898887746.\n",
      "\n",
      "Training on 177 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 178 epoch\n",
      "Training on epoch 178 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
      " Top K precision = 0.08775510204081632, recall = 0.0069509954682561124.\n",
      "Training on epoch 178 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08673469387755102, recall = 0.007508561302083237.\n",
      "Training on epoch 178 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.07899999999999997, recall = 0.0072191641531970585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 178 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08526315789473682, recall = 0.006554668062246613.\n",
      "Training on epoch 178 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08556701030927832, recall = 0.0064198388198366246.\n",
      "Training on epoch 178 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08541666666666663, recall = 0.007058910540734798.\n",
      "Training on epoch 178 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0829787234042553, recall = 0.006103623133885196.\n",
      "Training on epoch 178 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09999999999999992, recall = 0.007973574370844474.\n",
      "\n",
      "Training on 178 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999993, recall = 0.00755877212747478.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 179 epoch\n",
      "Training on epoch 179 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08854166666666664, recall = 0.007310229173797301.\n",
      "Training on epoch 179 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.10212765957446804, recall = 0.00897865356122821.\n",
      "Training on epoch 179 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08571428571428566, recall = 0.007040183721166636.\n",
      "Training on epoch 179 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.0813725490196078, recall = 0.007896204844870641.\n",
      "Training on epoch 179 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08064516129032254, recall = 0.007693531566345702.\n",
      "Training on epoch 179 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08602150537634407, recall = 0.0065099536272400765.\n",
      "Training on epoch 179 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08865979381443298, recall = 0.007610819753909253.\n",
      "Training on epoch 179 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.0959183673469387, recall = 0.00881356970492988.\n",
      "\n",
      "Training on 179 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999993, recall = 0.007571240955404952.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 180 epoch\n",
      "Training on epoch 180 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09901960784313722, recall = 0.007170783633110408.\n",
      "Training on epoch 180 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.06931818181818182, recall = 0.006306748269058896.\n",
      "Training on epoch 180 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08736842105263158, recall = 0.008447433079208474.\n",
      "Training on epoch 180 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.00814488797679424.\n",
      "Training on epoch 180 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08315789473684208, recall = 0.006826793508459886.\n",
      "Training on epoch 180 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09247311827956987, recall = 0.00759322449153321.\n",
      "Training on epoch 180 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.07499999999999998, recall = 0.007289077548663226.\n",
      "Training on epoch 180 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08526315789473683, recall = 0.006504493313284076.\n",
      "\n",
      "Training on 180 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n",
      "Training on the 181 epoch\n",
      "Training on epoch 181 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09042553191489358, recall = 0.007634539249968699.\n",
      "Training on epoch 181 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08124999999999996, recall = 0.008108573436307465.\n",
      "Training on epoch 181 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.10212765957446802, recall = 0.008318575975079302.\n",
      "Training on epoch 181 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08842105263157893, recall = 0.007302726857628533.\n",
      "Training on epoch 181 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09270833333333332, recall = 0.007762573703776445.\n",
      "Training on epoch 181 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09898989898989892, recall = 0.008582718188868771.\n",
      "Training on epoch 181 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08947368421052627, recall = 0.0072245938915459626.\n",
      "Training on epoch 181 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08988764044943817, recall = 0.006277895483958645.\n",
      "\n",
      "Training on 181 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474772.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08499999999999992, recall = 0.007382001755523101.\n",
      "\n",
      "Training on the 182 epoch\n",
      "Training on epoch 182 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08979591836734693, recall = 0.006956142614433177.\n",
      "Training on epoch 182 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08229166666666664, recall = 0.006637761810160208.\n",
      "Training on epoch 182 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07999999999999997, recall = 0.007780107334688392.\n",
      "Training on epoch 182 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.11684210526315783, recall = 0.009008139632164432.\n",
      "Training on epoch 182 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09166666666666666, recall = 0.0062708551556374175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 182 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07826086956521738, recall = 0.007809520256141569.\n",
      "Training on epoch 182 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08924731182795696, recall = 0.008208040606891008.\n",
      "Training on epoch 182 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08829787234042548, recall = 0.007960040761229671.\n",
      "\n",
      "Training on 182 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 183 epoch\n",
      "Training on epoch 183 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
      " Top K precision = 0.0829787234042553, recall = 0.0069130753606043305.\n",
      "Training on epoch 183 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08865979381443295, recall = 0.0073808915493043005.\n",
      "Training on epoch 183 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0978723404255318, recall = 0.008894746940585655.\n",
      "Training on epoch 183 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09270833333333334, recall = 0.008857390485943547.\n",
      "Training on epoch 183 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08041237113402058, recall = 0.006926669820756769.\n",
      "Training on epoch 183 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08681318681318681, recall = 0.008139035287020459.\n",
      "Training on epoch 183 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0703296703296703, recall = 0.008204438969261001.\n",
      "Training on epoch 183 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07717391304347822, recall = 0.007871448895857943.\n",
      "\n",
      "Training on 183 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 184 epoch\n",
      "Training on epoch 184 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.09888888888888889, recall = 0.00845075742084333.\n",
      "Training on epoch 184 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09263157894736837, recall = 0.008618704872825221.\n",
      "Training on epoch 184 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08979591836734693, recall = 0.005937149856914228.\n",
      "Training on epoch 184 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08899999999999997, recall = 0.0068491548091160126.\n",
      "Training on epoch 184 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08172043010752685, recall = 0.00831433934088163.\n",
      "Training on epoch 184 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09899999999999999, recall = 0.008820392893372667.\n",
      "Training on epoch 184 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09777777777777773, recall = 0.008065133445585081.\n",
      "Training on epoch 184 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08787878787878783, recall = 0.007691146019798942.\n",
      "\n",
      "Training on 184 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08949999999999995, recall = 0.007569571263543893.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 185 epoch\n",
      "Training on epoch 185 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08617021276595742, recall = 0.006435645771361703.\n",
      "Training on epoch 185 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10103092783505148, recall = 0.007551877635494181.\n",
      "Training on epoch 185 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.0824175824175824, recall = 0.007530831054845149.\n",
      "Training on epoch 185 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.07978723404255317, recall = 0.007441365128317227.\n",
      "Training on epoch 185 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.0081096749353115.\n",
      "Training on epoch 185 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.8e-05.\n",
      " Top K precision = 0.0945652173913043, recall = 0.006423071938072564.\n",
      "Training on epoch 185 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
      " Top K precision = 0.09166666666666666, recall = 0.008465089871540309.\n",
      "Training on epoch 185 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07582417582417583, recall = 0.005553479438975964.\n",
      "\n",
      "Training on 185 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08649999999999997, recall = 0.007386861754077144.\n",
      "\n",
      "Training on the 186 epoch\n",
      "Training on epoch 186 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09578947368421052, recall = 0.0067034594662267535.\n",
      "Training on epoch 186 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.1, recall = 0.009726851887521308.\n",
      "Training on epoch 186 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09361702127659571, recall = 0.00904156959116162.\n",
      "Training on epoch 186 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09680851063829782, recall = 0.007907043406486037.\n",
      "Training on epoch 186 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08924731182795696, recall = 0.008643701919450223.\n",
      "Training on epoch 186 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08163265306122448, recall = 0.0056457811100056815.\n",
      "Training on epoch 186 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08571428571428572, recall = 0.008157499903192336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 186 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.09175257731958761, recall = 0.00725467341943746.\n",
      "\n",
      "Training on 186 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.0889999999999999, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 187 epoch\n",
      "Training on epoch 187 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
      " Top K precision = 0.09021739130434779, recall = 0.00760276206391457.\n",
      "Training on epoch 187 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08453608247422675, recall = 0.0067929550089286.\n",
      "Training on epoch 187 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09560439560439558, recall = 0.009722555027432547.\n",
      "Training on epoch 187 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09583333333333328, recall = 0.008454835817969653.\n",
      "Training on epoch 187 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.07634408602150533, recall = 0.007061501005068632.\n",
      "Training on epoch 187 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09603960396039601, recall = 0.007896246388240456.\n",
      "Training on epoch 187 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.07849462365591396, recall = 0.0072253824889050595.\n",
      "Training on epoch 187 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08144329896907215, recall = 0.008287953870100822.\n",
      "\n",
      "Training on 187 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 188 epoch\n",
      "Training on epoch 188 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08737864077669899, recall = 0.008690194868644587.\n",
      "Training on epoch 188 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.0989361702127659, recall = 0.0076160492607524.\n",
      "Training on epoch 188 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.08199999999999999, recall = 0.00755777948110403.\n",
      "Training on epoch 188 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0818181818181818, recall = 0.008431567571330676.\n",
      "Training on epoch 188 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07941176470588235, recall = 0.0068478007578553005.\n",
      "Training on epoch 188 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.10210526315789469, recall = 0.008688264111495994.\n",
      "Training on epoch 188 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09263157894736838, recall = 0.00831888933289461.\n",
      "Training on epoch 188 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09882352941176464, recall = 0.006804790036191649.\n",
      "\n",
      "Training on 188 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999994, recall = 0.007546547188599471.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 189 epoch\n",
      "Training on epoch 189 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
      " Top K precision = 0.09680851063829783, recall = 0.007985398875809504.\n",
      "Training on epoch 189 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09578947368421047, recall = 0.008126272403890803.\n",
      "Training on epoch 189 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08367346938775508, recall = 0.008045968766073075.\n",
      "Training on epoch 189 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09166666666666663, recall = 0.008353213344286818.\n",
      "Training on epoch 189 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09042553191489362, recall = 0.007198715161653285.\n",
      "Training on epoch 189 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08659793814432988, recall = 0.008600522326773446.\n",
      "Training on epoch 189 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.085, recall = 0.007386850860501047.\n",
      "Training on epoch 189 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.08666666666666667, recall = 0.005337286368211281.\n",
      "\n",
      "Training on 189 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999998, recall = 0.007558772127474775.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 190 epoch\n",
      "Training on epoch 190 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.09263157894736837, recall = 0.008120045061996308.\n",
      "Training on epoch 190 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.09456521739130432, recall = 0.009799407560349421.\n",
      "Training on epoch 190 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.10444444444444441, recall = 0.007904990434498918.\n",
      "Training on epoch 190 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
      " Top K precision = 0.09900990099009896, recall = 0.008678788266044499.\n",
      "Training on epoch 190 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0833333333333333, recall = 0.007427600779460645.\n",
      "Training on epoch 190 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.09489795918367344, recall = 0.006699683463556841.\n",
      "Training on epoch 190 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.07553191489361699, recall = 0.006686711091804506.\n",
      "Training on epoch 190 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08556701030927834, recall = 0.007117416247993892.\n",
      "\n",
      "Training on 190 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08849999999999997, recall = 0.007492982653790566.\n",
      "\n",
      "Training on the 191 epoch\n",
      "Training on epoch 191 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
      " Top K precision = 0.08351648351648348, recall = 0.0073261083184514.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 191 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0782178217821782, recall = 0.007188342851273986.\n",
      "Training on epoch 191 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08804347826086956, recall = 0.007547128839081805.\n",
      "Training on epoch 191 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.08541666666666665, recall = 0.00812566623933101.\n",
      "Training on epoch 191 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09599999999999996, recall = 0.008120803816856318.\n",
      "Training on epoch 191 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.10425531914893613, recall = 0.00845638479125189.\n",
      "Training on epoch 191 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09569892473118276, recall = 0.006556007372427611.\n",
      "Training on epoch 191 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07849462365591398, recall = 0.006723199000042407.\n",
      "\n",
      "Training on 191 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n",
      "\n",
      "Training on the 192 epoch\n",
      "Training on epoch 192 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.07979797979797977, recall = 0.006663978321219634.\n",
      "Training on epoch 192 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.0904255319148936, recall = 0.00707192138578845.\n",
      "Training on epoch 192 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.08437499999999999, recall = 0.007680640505571257.\n",
      "Training on epoch 192 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.07938144329896905, recall = 0.006295902526127091.\n",
      "Training on epoch 192 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.08387096774193548, recall = 0.007355655514975324.\n",
      "Training on epoch 192 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08199999999999998, recall = 0.007558424465595133.\n",
      "Training on epoch 192 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08510638297872339, recall = 0.008445571387228777.\n",
      "Training on epoch 192 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
      " Top K precision = 0.08888888888888886, recall = 0.008420170505545178.\n",
      "\n",
      "Training on 192 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 193 epoch\n",
      "Training on epoch 193 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.08695652173913039, recall = 0.008199148431857213.\n",
      "Training on epoch 193 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.06956521739130433, recall = 0.006619222260967111.\n",
      "Training on epoch 193 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08265306122448977, recall = 0.006049189482727949.\n",
      "Training on epoch 193 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08958333333333328, recall = 0.006968863881148192.\n",
      "Training on epoch 193 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.08333333333333333, recall = 0.007353258572146678.\n",
      "Training on epoch 193 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.08089887640449439, recall = 0.007623749476519958.\n",
      "Training on epoch 193 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09789473684210521, recall = 0.009678718639533604.\n",
      "Training on epoch 193 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.07826086956521737, recall = 0.006226126810128734.\n",
      "\n",
      "Training on 193 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.007558772127474772.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 194 epoch\n",
      "Training on epoch 194 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09499999999999996, recall = 0.009605242247540531.\n",
      "Training on epoch 194 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
      " Top K precision = 0.0913043478260869, recall = 0.007911575845101514.\n",
      "Training on epoch 194 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09690721649484531, recall = 0.007916990059064398.\n",
      "Training on epoch 194 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.08437499999999998, recall = 0.007493646480006545.\n",
      "Training on epoch 194 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
      " Top K precision = 0.10416666666666664, recall = 0.009631917864275056.\n",
      "Training on epoch 194 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.07156862745098039, recall = 0.00612712250930756.\n",
      "Training on epoch 194 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08279569892473111, recall = 0.006369241793427279.\n",
      "Training on epoch 194 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.09893617021276593, recall = 0.006987581773552044.\n",
      "\n",
      "Training on 194 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999994, recall = 0.007527126557854521.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 195 epoch\n",
      "Training on epoch 195 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.08111111111111106, recall = 0.007495857213659792.\n",
      "Training on epoch 195 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
      " Top K precision = 0.08021978021978018, recall = 0.00825541280380987.\n",
      "Training on epoch 195 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07826086956521737, recall = 0.007577765829541703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 195 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.08260869565217392, recall = 0.006123686578584355.\n",
      "Training on epoch 195 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10106382978723398, recall = 0.009318727418013787.\n",
      "Training on epoch 195 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09278350515463915, recall = 0.006714642927562172.\n",
      "Training on epoch 195 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.09999999999999996, recall = 0.007195214246328658.\n",
      "Training on epoch 195 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.0895833333333333, recall = 0.007279298857097782.\n",
      "\n",
      "Training on 195 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007527126557854525.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08799999999999995, recall = 0.007460746665816737.\n",
      "\n",
      "Training on the 196 epoch\n",
      "Training on epoch 196 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09519230769230765, recall = 0.007040493563530477.\n",
      "Training on epoch 196 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07653061224489795, recall = 0.007102967800850328.\n",
      "Training on epoch 196 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.07821782178217822, recall = 0.0072242357290959545.\n",
      "Training on epoch 196 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08791208791208792, recall = 0.008202256042190128.\n",
      "Training on epoch 196 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08041237113402061, recall = 0.008308622269507992.\n",
      "Training on epoch 196 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.08199999999999998, recall = 0.008498887859767091.\n",
      "Training on epoch 196 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.08510638297872336, recall = 0.006565075769272635.\n",
      "Training on epoch 196 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07291666666666664, recall = 0.006444374334526981.\n",
      "\n",
      "Training on 196 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999991, recall = 0.0075587721274747765.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 197 epoch\n",
      "Training on epoch 197 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.0861702127659574, recall = 0.0071838623252922845.\n",
      "Training on epoch 197 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.09456521739130434, recall = 0.008415718864901134.\n",
      "Training on epoch 197 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07640449438202244, recall = 0.007111046408563138.\n",
      "Training on epoch 197 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09354838709677418, recall = 0.006946576766789594.\n",
      "Training on epoch 197 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.07956989247311826, recall = 0.007758943306096601.\n",
      "Training on epoch 197 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
      " Top K precision = 0.08191489361702127, recall = 0.0070113680826974605.\n",
      "Training on epoch 197 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
      " Top K precision = 0.088, recall = 0.006915195714697082.\n",
      "Training on epoch 197 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
      " Top K precision = 0.10430107526881714, recall = 0.007439140527632136.\n",
      "\n",
      "Training on 197 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 198 epoch\n",
      "Training on epoch 198 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
      " Top K precision = 0.1030927835051546, recall = 0.009039451343189803.\n",
      "Training on epoch 198 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
      " Top K precision = 0.06630434782608695, recall = 0.00479603732417609.\n",
      "Training on epoch 198 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0927083333333333, recall = 0.008494045394976535.\n",
      "Training on epoch 198 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
      " Top K precision = 0.09591836734693877, recall = 0.008669699845838435.\n",
      "Training on epoch 198 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.10105263157894732, recall = 0.009285905303245525.\n",
      "Training on epoch 198 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.09032258064516127, recall = 0.007083880818698543.\n",
      "Training on epoch 198 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
      " Top K precision = 0.09468085106382979, recall = 0.006817021269906571.\n",
      "Training on epoch 198 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
      " Top K precision = 0.09010989010989008, recall = 0.008123825846575913.\n",
      "\n",
      "Training on 198 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08849999999999997, recall = 0.007549373631234174.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
      "\n",
      "Training on the 199 epoch\n",
      "Training on epoch 199 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09680851063829783, recall = 0.007466932006279325.\n",
      "Training on epoch 199 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
      " Top K precision = 0.0965116279069767, recall = 0.0071640372252349226.\n",
      "Training on epoch 199 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.09052631578947365, recall = 0.00724069418940204.\n",
      "Training on epoch 199 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
      " Top K precision = 0.07999999999999999, recall = 0.00785597288613177.\n",
      "Training on epoch 199 minibatch 401/782 completed\n",
      " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
      " Top K precision = 0.0801980198019802, recall = 0.006591624455577129.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on epoch 199 minibatch 501/782 completed\n",
      " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.08541666666666664, recall = 0.006768065435901041.\n",
      "Training on epoch 199 minibatch 601/782 completed\n",
      " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
      " Top K precision = 0.09072164948453607, recall = 0.008087513743851317.\n",
      "Training on epoch 199 minibatch 701/782 completed\n",
      " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
      " Top K precision = 0.08659793814432988, recall = 0.006719491509652895.\n",
      "\n",
      "Training on 199 epoch completed.\n",
      " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
      " Training top K precision = 0.08899999999999997, recall = 0.007558772127474777.\n",
      " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.08949999999999995, recall = 0.0075682778308968305.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples_train=samples_train.to(device)\n",
    "samples_val=samples_val.to(device)\n",
    "samples_test=samples_test.to(device)\n",
    "train_mask=train_mask.to(device)\n",
    "val_mask=val_mask.to(device)\n",
    "test_mask=test_mask.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "print(f\"#Training samples: {len(samples_train)}\",\n",
    "      f\"#Validation samples: {len(samples_val)}\",\n",
    "      f\"#Test samples: {len(samples_test)}\")\n",
    "\n",
    "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
    "print(\"Optimizer:\", optimizer)\n",
    "\n",
    "epochs_tracked = []\n",
    "train_topks = []\n",
    "val_topks = []\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"Training on the {} epoch\".format(epoch))\n",
    "    lightGCN.train()\n",
    "    loss_sum = 0\n",
    "    # Shuffle the order of rows.\n",
    "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
    "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        current_batch = \\\n",
    "            samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
    "        # Shuffle the order of rows.\n",
    "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
    "        users = current_batch[:, 0:1]\n",
    "        pos = current_batch[:, 1:2]\n",
    "        neg = current_batch[:, 2:3]\n",
    "\n",
    "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, data,\n",
    "                                  train_mask)\n",
    "        reg_loss = reg_loss * weight_decay\n",
    "        loss = loss + reg_loss\n",
    "        \n",
    "        loss_sum += loss.detach()\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss_list.append(loss)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
    "            all_users = torch.linspace(start=0,\n",
    "                                       end=n_users - 1, steps=n_users).long()\n",
    "            user_indices = current_batch[:, 0]\n",
    "            user_indices = user_indices.repeat(2).long()\n",
    "            item_indices = torch.cat(\n",
    "                (current_batch[:, 1], current_batch[:, 2])).long()\n",
    "            pred = getUsersRating(lightGCN,\n",
    "                                  all_users,\n",
    "                                  data)[user_indices, item_indices]\n",
    "            truth = data[\"edge_index\"][user_indices, item_indices]\n",
    "            topk_precision, topk_recall = \\\n",
    "                personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
    "\n",
    "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
    "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
    "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
    "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
    "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
    "    \n",
    "\n",
    "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
    "        epochs_tracked.append(epoch)\n",
    "\n",
    "        # evaluation on both the trainisng and validation set\n",
    "        lightGCN.eval()\n",
    "        # predict on the training set\n",
    "        users = samples_train[:, 0:1]\n",
    "        user_indices = samples_train[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat(\n",
    "            (samples_train[:, 1], samples_train[:, 2])).long()\n",
    "        pred = getUsersRating(lightGCN,\n",
    "                              users[:,0],\n",
    "                              data)[user_indices, item_indices]\n",
    "        truth = data[\"edge_index\"][users.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        train_topk_precision, train_topk_recall = \\\n",
    "            personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
    "        train_topks.append((train_topk_precision, train_topk_recall))\n",
    "\n",
    "        # predict on the validation set\n",
    "        users_val = samples_val[:, 0:1]\n",
    "        pos_val = samples_val[:, 1:2]\n",
    "        neg_val = samples_val[:, 2:3]\n",
    "\n",
    "        loss_val, reg_loss_val = bpr_loss(\n",
    "            lightGCN, users_val, pos_val, neg_val, data, val_mask)\n",
    "        reg_loss_val = reg_loss_val * weight_decay\n",
    "        loss_val = loss_val + reg_loss_val\n",
    "        val_loss_list.append(loss_val)\n",
    "        \n",
    "\n",
    "        # predict on the validation set\n",
    "        user_indices = samples_val[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
    "        pred_val = getUsersRating(lightGCN,\n",
    "                                  users_val[:,0],\n",
    "                                  data)[user_indices, item_indices]\n",
    "        truth_val = data[\"edge_index\"][users_val.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        val_topk_precision, val_topk_recall = \\\n",
    "            personalized_topk(pred_val, K, user_indices, data[\"edge_index\"])\n",
    "        val_topks.append((val_topk_precision, val_topk_recall))\n",
    "\n",
    "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
    "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
    "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
    "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
    "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
    "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))\n",
    "torch.save(lightGCN.state_dict(), 'checkpoint_latest.pth')\n",
    "# download checkpoint file\n",
    "# files.download('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77xV_pCdAqV4"
   },
   "source": [
    "### Plot top K precision over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "DhWgVYTn6F05",
    "outputId": "a6442b24-8075-48a6-c42c-601c3d3bb5d4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_tracked, [precision for precision, _ in train_topks],\n",
    "         label=\"Train\")\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in val_topks],\n",
    "         label=\"Val\")\n",
    "plt.ylabel(f\"Top {K} precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRyN5RWZAtJB"
   },
   "source": [
    "### Plot top K recall over epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ryhaVfnL9cf3",
    "outputId": "1ae19764-2769-4b3e-dc15-21b3f0b5f727"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_tracked, [recall for _, recall in train_topks],\n",
    "         label=\"Train\")\n",
    "plt.plot(epochs_tracked, [recall for _, recall in val_topks],\n",
    "         label=\"Val\")\n",
    "plt.ylabel(f\"Top {K} recall\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved pytorch model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGCN(64, 64, num_layers=5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightGCN = LightGCN(model_config, device=device)\n",
    "lightGCN.load_state_dict(torch.load('checkpoint.pth'))\n",
    "lightGCN.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_loss_list)), [k.detach().float() for k in train_loss_list],\n",
    "         label=\"Train\")\n",
    "# plt.plot(epochs_tracked, [k.detach().float() for k in val_loss_list],\n",
    "#          label=\"Val\")\n",
    "plt.ylabel(f\"Train BPR Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7odzij5Av3N"
   },
   "source": [
    "## Test\n",
    "\n",
    "After training, let's test our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJnetNBG6C_k",
    "outputId": "c27552bc-a116-4c68-9c81-8bdf7d8e64b2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed after 100 epochs\n",
      "tensor(0.6931, grad_fn=<MeanBackward0>) tensor(0.0003, grad_fn=<MulBackward0>)\n",
      "Average bpr_loss on the test set is 7e-06, and regularization loss is 0.0.\n",
      " Top K precision = 0.08949999999999995, recall = 0.0077439573126599605.\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "lightGCN.eval()\n",
    "print(\"Training completed after {} epochs\".format(epochs))\n",
    "\n",
    "users_test = samples_test[:, 0:1]\n",
    "pos_test = samples_test[:, 1:2]\n",
    "neg_test = samples_test[:, 2:3]\n",
    "\n",
    "loss_test, reg_loss_test = bpr_loss(\n",
    "    lightGCN, users_test, pos_test, neg_test, data, test_mask)\n",
    "reg_loss_test = reg_loss_test * weight_decay\n",
    "print(loss_test,reg_loss_test)\n",
    "\n",
    "# predict on the test set\n",
    "user_indices = samples_test[:, 0]\n",
    "user_indices = user_indices.repeat(2).long()\n",
    "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
    "# pdb.set_trace()\n",
    "pred_test = getUsersRating(lightGCN, users_test[:,0], data)\\\n",
    "    [user_indices, item_indices]\n",
    "truth_test = data[\"edge_index\"][users_test.long()[:,0]]\\\n",
    "    [user_indices, item_indices]\n",
    "test_topk_precision, test_topk_recall = personalized_topk(\n",
    "    pred_test, K, user_indices, data[\"edge_index\"])\n",
    "\n",
    "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\".format(round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
    "                                                                                                round(float(reg_loss_test/len(samples_test)), 6)),\n",
    "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
    "\n",
    "# Save model embeddings.\n",
    "torch.save(lightGCN, config_dict[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below function can be used to get_predictions for a given user_id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 0.0 []\n",
      "194 3.0 ['Toy Story (1995)', 'Jumanji (1995)', 'Tom and Huck (1995)']\n",
      "162 4.0 ['GoldenEye (1995)', 'Sabrina (1995)', 'Toy Story (1995)', 'Jumanji (1995)']\n",
      "156 4.0 ['Heat (1995)', 'Sabrina (1995)', 'Toy Story (1995)', 'Jumanji (1995)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.275, 0.008615040832555914)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def demo_for_a_user(user_id, data,number_samples_per_user):\n",
    "    \"\"\"\n",
    "    Function is used to capture predictions for a given user or list of users\n",
    "    Input: List of user ids\n",
    "    Return: List of movies predicted by the model for the given user\n",
    "    \"\"\"\n",
    "    movies_df = pd.read_table('./raw/ml-1m/movies.dat', sep='::', \n",
    "                               header=None, engine='python',\n",
    "                               encoding='latin-1',names=['movie_id', 'title', 'genres'])\n",
    "    samples= []\n",
    "    \n",
    "#     users= torch.tensor([[x] for x in user_id])\n",
    "#     truth_items= data['edge_iandex'][useras.long()]\n",
    "    all_items = set(range(len(data[\"items\"])))\n",
    "    for user_index in user_id:\n",
    "        \n",
    "        pos_items = set(\n",
    "            torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
    "        unknown_items = all_items.differenace(\n",
    "            set(\n",
    "                torch.nonzero(\n",
    "                    data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
    "        neg_items = all_items.difference(\n",
    "            set(pos_items)).difference(set(unknown_items))\n",
    "#         print(user_index, len(pos_items), len(neg_items),unknown_items)\n",
    "#         print(neg_items)\n",
    "#         break\n",
    "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
    "                    len(unknown_items.union(neg_items)) == 0:\n",
    "                continue\n",
    "        for _ in range(num_samples_per_user):\n",
    "#             print(user_index,_)\n",
    "            if len(pos_items) == 0:\n",
    "                pos_item_index = random.choice(\n",
    "                    unknown_items)\n",
    "            else:\n",
    "                pos_item_index = random.choice(list(pos_items))\n",
    "            if len(neg_items) == 0:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(unknown_items) )\n",
    "            else:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(neg_items))\n",
    "            samples.append((user_index, pos_item_index, neg_item_index))\n",
    "#     print(samples)\n",
    "    samples = torch.tensor(samples, dtype=torch.int32)\n",
    "    \n",
    "    ### Invoking Prediction Pipeline\n",
    "    users_test= samples[:, 0:1]\n",
    "    user_indices = samples[:, 0]\n",
    "    user_indices = user_indices.repeat(2).long()\n",
    "    item_indices = torch.cat((samples[:, 1], samples[:, 2])).long()\n",
    "    pred_test = getUsersRating(lightGCN, users_test[:,0], data)\\\n",
    "    [user_indices, item_indices]\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "#     print(pred_test)\n",
    "    truth_test = data[\"edge_index\"][users_test.long()[:,0]]\\\n",
    "    [user_indices, item_indices]\n",
    "    per_user_preds = collections.defaultdict(list)\n",
    "    for index, user in enumerate(user_indices):\n",
    "        per_user_preds[user.item()].append(pred_test[index].item())\n",
    "#     import pdb\n",
    "    precisions = 0.0\n",
    "    recalls = 0.0\n",
    "    edge_index= data['edge_index']\n",
    "    for user, preds in per_user_preds.items():\n",
    "        movies_list= []\n",
    "        while len(preds) < K:\n",
    "            preds.append(random.choice(range(edge_index.shape[1])))\n",
    "        \n",
    "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
    "        correct_preds = edge_index[user, top_items].sum().item()\n",
    "#         pdb.set_trace()\n",
    "        for idx, val in enumerate(edge_index[user, top_items]):\n",
    "            if val==1:\n",
    "#                 print(movies_df.iloc[top_items[idx].item(), :])\n",
    "#                 movies_list.append((movies_df.loc[top_items[idx].item(), 'title'],\n",
    "#                                    movies_df.loc[top_items[idx].item(), 'genres']))\n",
    "                movies_list.append((movies_df.loc[top_items[idx].item(), 'title']))\n",
    "#                 pdb.set_trace()\n",
    "        print(user,correct_preds, movies_list)\n",
    "#         print(user, movies_list)\n",
    "        total_pos = edge_index[user].sum().item()\n",
    "        precisions += correct_preds / K\n",
    "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
    "    num_users = len(user_indices.unique())\n",
    "    return precisions / num_users, recalls / num_users\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sam = demo_for_a_user(list(range(200)), data, 500)\n",
    "sam= demo_for_a_user([135,194,162,156], data, 500)\n",
    "# sam= demo_for_a_user([199,112,115,128,14],data,500)\n",
    "sam\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above top10 precision can be interpreted as \"Out of 10 recommendations that we give,on an average atleast  one item will have rating more than 3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "movie-recommendation-LightGCN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
